{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1aOE45_RFEZLIKxgdfOZJREAijydzp_Zc",
      "authorship_tag": "ABX9TyMAgdzaMUkut7vIT9hvmDUM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eoinleen/Protein-design-random/blob/main/Extracting_stats_from_AF3_directories_v1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 342
        },
        "id": "Mh90oPqUZNR1",
        "outputId": "05c0b66c-34da-4edb-c136-381debfa2501"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "\n",
            "Preview of averaged results:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  fold_id model_type  num_models model_nums  avg_iptm  avg_ptm  \\\n",
              "0    1010         24           5  0,1,2,3,4     0.854    0.890   \n",
              "1  110287      mpnn3           5  0,1,2,3,4     0.704    0.774   \n",
              "2  150447      mpnn3           5  0,1,2,3,4     0.788    0.844   \n",
              "3  164418      mpnn2           5  0,1,2,3,4     0.296    0.582   \n",
              "4  164418      mpnn3           5  0,1,2,3,4     0.856    0.888   \n",
              "\n",
              "   avg_ranking_score  avg_has_clash  avg_fraction_disordered  avg_binder_ptm  \\\n",
              "0              0.862          False                    False           0.878   \n",
              "1              0.716          False                    False           0.758   \n",
              "2              0.800          False                    False           0.856   \n",
              "3              0.354          False                    False           0.854   \n",
              "4              0.862          False                    False           0.884   \n",
              "\n",
              "   ...  avg_binder_avg_plddt  avg_ub1_avg_plddt  avg_ub2_avg_plddt  \\\n",
              "0  ...             92.741425          90.393442          90.287202   \n",
              "1  ...             78.077954          89.142291          87.848592   \n",
              "2  ...             86.565249          90.071347          87.909204   \n",
              "3  ...             82.539048          78.215390          79.281446   \n",
              "4  ...             91.233013          89.212333          89.441769   \n",
              "\n",
              "   avg_binder_ub1_pae_min  avg_binder_ub2_pae_min  avg_ub1_ub2_pae_min  \\\n",
              "0                   1.240                   1.470                1.674   \n",
              "1                   2.310                   2.838                2.332   \n",
              "2                   1.712                   2.592                2.014   \n",
              "3                   8.942                   7.788               14.482   \n",
              "4                   1.266                   1.594                1.752   \n",
              "\n",
              "   best_model_num  best_model_iptm  best_model_ranking_score  \\\n",
              "0               0             0.86                      0.87   \n",
              "1               0             0.71                      0.72   \n",
              "2               0             0.80                      0.81   \n",
              "3               0             0.34                      0.39   \n",
              "4               0             0.86                      0.87   \n",
              "\n",
              "   best_model_binder_ub_iptm  \n",
              "0                      0.845  \n",
              "1                      0.665  \n",
              "2                      0.765  \n",
              "3                      0.320  \n",
              "4                      0.850  \n",
              "\n",
              "[5 rows x 26 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-924b45b1-20e3-4e44-a1ea-c3cd6f3424fc\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fold_id</th>\n",
              "      <th>model_type</th>\n",
              "      <th>num_models</th>\n",
              "      <th>model_nums</th>\n",
              "      <th>avg_iptm</th>\n",
              "      <th>avg_ptm</th>\n",
              "      <th>avg_ranking_score</th>\n",
              "      <th>avg_has_clash</th>\n",
              "      <th>avg_fraction_disordered</th>\n",
              "      <th>avg_binder_ptm</th>\n",
              "      <th>...</th>\n",
              "      <th>avg_binder_avg_plddt</th>\n",
              "      <th>avg_ub1_avg_plddt</th>\n",
              "      <th>avg_ub2_avg_plddt</th>\n",
              "      <th>avg_binder_ub1_pae_min</th>\n",
              "      <th>avg_binder_ub2_pae_min</th>\n",
              "      <th>avg_ub1_ub2_pae_min</th>\n",
              "      <th>best_model_num</th>\n",
              "      <th>best_model_iptm</th>\n",
              "      <th>best_model_ranking_score</th>\n",
              "      <th>best_model_binder_ub_iptm</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1010</td>\n",
              "      <td>24</td>\n",
              "      <td>5</td>\n",
              "      <td>0,1,2,3,4</td>\n",
              "      <td>0.854</td>\n",
              "      <td>0.890</td>\n",
              "      <td>0.862</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0.878</td>\n",
              "      <td>...</td>\n",
              "      <td>92.741425</td>\n",
              "      <td>90.393442</td>\n",
              "      <td>90.287202</td>\n",
              "      <td>1.240</td>\n",
              "      <td>1.470</td>\n",
              "      <td>1.674</td>\n",
              "      <td>0</td>\n",
              "      <td>0.86</td>\n",
              "      <td>0.87</td>\n",
              "      <td>0.845</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>110287</td>\n",
              "      <td>mpnn3</td>\n",
              "      <td>5</td>\n",
              "      <td>0,1,2,3,4</td>\n",
              "      <td>0.704</td>\n",
              "      <td>0.774</td>\n",
              "      <td>0.716</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0.758</td>\n",
              "      <td>...</td>\n",
              "      <td>78.077954</td>\n",
              "      <td>89.142291</td>\n",
              "      <td>87.848592</td>\n",
              "      <td>2.310</td>\n",
              "      <td>2.838</td>\n",
              "      <td>2.332</td>\n",
              "      <td>0</td>\n",
              "      <td>0.71</td>\n",
              "      <td>0.72</td>\n",
              "      <td>0.665</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>150447</td>\n",
              "      <td>mpnn3</td>\n",
              "      <td>5</td>\n",
              "      <td>0,1,2,3,4</td>\n",
              "      <td>0.788</td>\n",
              "      <td>0.844</td>\n",
              "      <td>0.800</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0.856</td>\n",
              "      <td>...</td>\n",
              "      <td>86.565249</td>\n",
              "      <td>90.071347</td>\n",
              "      <td>87.909204</td>\n",
              "      <td>1.712</td>\n",
              "      <td>2.592</td>\n",
              "      <td>2.014</td>\n",
              "      <td>0</td>\n",
              "      <td>0.80</td>\n",
              "      <td>0.81</td>\n",
              "      <td>0.765</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>164418</td>\n",
              "      <td>mpnn2</td>\n",
              "      <td>5</td>\n",
              "      <td>0,1,2,3,4</td>\n",
              "      <td>0.296</td>\n",
              "      <td>0.582</td>\n",
              "      <td>0.354</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0.854</td>\n",
              "      <td>...</td>\n",
              "      <td>82.539048</td>\n",
              "      <td>78.215390</td>\n",
              "      <td>79.281446</td>\n",
              "      <td>8.942</td>\n",
              "      <td>7.788</td>\n",
              "      <td>14.482</td>\n",
              "      <td>0</td>\n",
              "      <td>0.34</td>\n",
              "      <td>0.39</td>\n",
              "      <td>0.320</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>164418</td>\n",
              "      <td>mpnn3</td>\n",
              "      <td>5</td>\n",
              "      <td>0,1,2,3,4</td>\n",
              "      <td>0.856</td>\n",
              "      <td>0.888</td>\n",
              "      <td>0.862</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0.884</td>\n",
              "      <td>...</td>\n",
              "      <td>91.233013</td>\n",
              "      <td>89.212333</td>\n",
              "      <td>89.441769</td>\n",
              "      <td>1.266</td>\n",
              "      <td>1.594</td>\n",
              "      <td>1.752</td>\n",
              "      <td>0</td>\n",
              "      <td>0.86</td>\n",
              "      <td>0.87</td>\n",
              "      <td>0.850</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 26 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-924b45b1-20e3-4e44-a1ea-c3cd6f3424fc')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-924b45b1-20e3-4e44-a1ea-c3cd6f3424fc button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-924b45b1-20e3-4e44-a1ea-c3cd6f3424fc');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ec8e1caa-9132-451b-83d2-81f29fef50a7\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ec8e1caa-9132-451b-83d2-81f29fef50a7')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ec8e1caa-9132-451b-83d2-81f29fef50a7 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Detailed log saved to: /content/drive/MyDrive/PDB-files/AF3-recalc_folds_2025_03_08_19_33/AF3_ANALYSIS_RESULTS/af3_analysis_log_20250308_214622.txt\n"
          ]
        }
      ],
      "source": [
        "# ========================================================================\n",
        "# AlphaFold3 K11-Ub2 Binder Analysis Script\n",
        "# ========================================================================\n",
        "#\n",
        "# PURPOSE:\n",
        "# This script analyzes AlphaFold3 prediction results for K11-Ub2 binder designs.\n",
        "# It extracts confidence metrics, calculates pLDDT values, and generates\n",
        "# visualizations to help evaluate and compare different binder designs.\n",
        "#\n",
        "# HOW TO USE THIS SCRIPT:\n",
        "# 1. Upload this script to Google Colab\n",
        "# 2. Change the 'base_dir' variable in the main() function to point to your data folder\n",
        "#    (e.g., '/content/drive/MyDrive/My_AF3_Results')\n",
        "# 3. Run the script\n",
        "# 4. Check the output directory for results (CSV files, plots, and log file)\n",
        "#\n",
        "# INPUT DATA REQUIREMENTS:\n",
        "# - JSON confidence files (format: *summary_confidences_*.json)\n",
        "# - PDB/CIF structure files in the same directories as their JSON files\n",
        "# - File naming should include fold_id and model numbers\n",
        "#\n",
        "# WHAT THIS SCRIPT DOES:\n",
        "# 1. Finds all JSON confidence files in the specified directory and subdirectories\n",
        "# 2. Parses each JSON file to extract metrics like ipTM, pTM, and chain interactions\n",
        "# 3. Locates the corresponding PDB/CIF file for each JSON file\n",
        "# 4. Calculates per-residue and per-chain average pLDDT values from PDB files\n",
        "# 5. Computes averages across models (0-4) for each fold_id/model_type combination\n",
        "# 6. Generates visualizations of:\n",
        "#    - Binder Quality (pLDDT) vs Binding Interface Quality (ipTM)\n",
        "#    - Binder interaction with Ub1 vs Ub2\n",
        "# 7. Creates a detailed log file documenting the analysis process\n",
        "# 8. Saves raw and averaged data as CSV files\n",
        "#\n",
        "# OUTPUTS:\n",
        "# - af3_raw_results.csv: All metrics for each individual model\n",
        "# - af3_averaged_results.csv: Metrics averaged across models for each design\n",
        "# - binder_quality_vs_interface.png: Plot of binder pLDDT vs interface ipTM\n",
        "# - binder_ub1_vs_ub2_interaction.png: Plot of binder interaction with Ub1 vs Ub2\n",
        "# - af3_analysis_log_*.txt: Detailed log of the analysis process\n",
        "#\n",
        "# KEY METRICS EXPLAINED:\n",
        "# - iptm: Interface predicted TM-score, measures quality of interface prediction\n",
        "# - binder_ub1_iptm: Interface ipTM between binder (A) and first ubiquitin (B)\n",
        "# - binder_ub2_iptm: Interface ipTM between binder (A) and second ubiquitin (C)\n",
        "# - binder_ub_iptm: Average of binder_ub1_iptm and binder_ub2_iptm\n",
        "# - binder_avg_plddt: Average confidence score for the binder, calculated\n",
        "#   by averaging B-factor values per residue, then averaging those per chain\n",
        "# - composite_score: Average of avg_iptm and avg_binder_ub_iptm\n",
        "#\n",
        "# TROUBLESHOOTING:\n",
        "# - If no JSON files are found: Check the 'base_dir' path and make sure files match expected patterns\n",
        "# - If no PDB files are matched: Check filenames and directory structure\n",
        "# - If missing data in CSV: Check log file for warnings about specific metrics\n",
        "# - If no visualizations: Make sure required metrics are available\n",
        "#\n",
        "# UNDERSTANDING THE CHAIN NAMES:\n",
        "# - Chain A: The binder\n",
        "# - Chain B: First ubiquitin (Ub1)\n",
        "# - Chain C: Second ubiquitin (Ub2)\n",
        "#\n",
        "# REQUIREMENTS:\n",
        "# - Python packages: pandas, numpy, matplotlib, seaborn, biopython\n",
        "#\n",
        "# ========================================================================\n",
        "# Authors:\n",
        "# - Claude from Anthropic (Primary implementation and documentation)\n",
        "# - Your Name (Project design, use case definition, and testing)\n",
        "# - St Jimmy (Moral support and asking questions no one else would think to ask)\n",
        "#\n",
        "# Date: 2025-03-08\n",
        "# Version: 1.0\n",
        "# ========================================================================\n",
        "#\n",
        "# Note for Jimmy: Yes, this is the right script. Just run it and it will work.\n",
        "# No, don't change anything unless you know what you're doing. Yes, it's\n",
        "# supposed to take that long to run. No, the warnings are normal.\n",
        "#\n",
        "# ========================================================================\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Main execution function that processes data and generates outputs.\n",
        "    \"\"\"\n",
        "    # Set the base directory to your mounted Google Drive folder\n",
        "    # Update this path to match your Google Drive structure\n",
        "    base_dir = '/content/drive/MyDrive/PDB-files/AF3-recalc_folds_2025_03_08_19_33'\n",
        "    output_dir = '/content/drive/MyDrive/PDB-files/AF3-recalc_folds_2025_03_08_19_33/AF3_ANALYSIS_RESULTS'\n",
        "\n",
        "    # Create output directory and set up logging\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    log_file = setup_logging(output_dir)\n",
        "\n",
        "    logging.info(\"Starting AlphaFold3 K11-Ub2 binder analysis...\")\n",
        "    logging.info(f\"Base directory: {base_dir}\")\n",
        "    logging.info(f\"Output directory: {output_dir}\")\n",
        "\n",
        "    # Process all folders\n",
        "    df = process_folder(base_dir)\n",
        "\n",
        "    # Check if we have data\n",
        "    if df.empty:\n",
        "        logging.error(\"No data was found or processed. Please check your file paths and formats.\")\n",
        "        return None, None, log_file\n",
        "\n",
        "    # Save the raw DataFrame to CSV\n",
        "    raw_csv_path = os.path.join(output_dir, 'af3_raw_results.csv')\n",
        "    df.to_csv(raw_csv_path, index=False)\n",
        "    logging.info(f\"Raw analysis results saved to {raw_csv_path}\")\n",
        "\n",
        "    # Check for any rows with missing critical data\n",
        "    critical_cols = ['fold_id', 'model_type', 'model_num', 'iptm']\n",
        "    available_critical_cols = [col for col in critical_cols if col in df.columns]\n",
        "\n",
        "    if available_critical_cols:\n",
        "        missing_data = df[df[available_critical_cols].isna().any(axis=1)]\n",
        "        if not missing_data.empty:\n",
        "            logging.warning(f\"{len(missing_data)} rows have missing critical data\")\n",
        "            logging.warning(\"Sample of rows with missing data:\")\n",
        "            for idx, row in missing_data.head().iterrows():\n",
        "                logging.warning(f\"  Row {idx}: {row[available_critical_cols].to_dict()}\")\n",
        "\n",
        "    # Calculate averages across models 0-4 for each fold\n",
        "    try:\n",
        "        logging.info(\"Calculating model averages...\")\n",
        "        avg_df = calculate_model_averages(df)\n",
        "\n",
        "        if avg_df.empty:\n",
        "            logging.error(\"Failed to calculate model averages. Check the logs for details.\")\n",
        "            return df, None, log_file\n",
        "\n",
        "        # Save the averaged DataFrame to CSV\n",
        "        avg_csv_path = os.path.join(output_dir, 'af3_averaged_results.csv')\n",
        "        avg_df.to_csv(avg_csv_path, index=False)\n",
        "        logging.info(f\"Averaged analysis results saved to {avg_csv_path}\")\n",
        "\n",
        "        # Generate visualizations for the averaged data\n",
        "        generate_visualizations(df, avg_df, output_dir)\n",
        "\n",
        "        # Display summary statistics for the averaged data\n",
        "        logging.info(\"Summary Statistics for Averaged Data:\")\n",
        "\n",
        "        # List of metrics to show in summary\n",
        "        summary_metrics = ['avg_iptm', 'avg_binder_ub_iptm', 'avg_binder_plddt']\n",
        "        available_metrics = [m for m in summary_metrics if m in avg_df.columns]\n",
        "\n",
        "        if available_metrics:\n",
        "            # Calculate descriptive statistics\n",
        "            summary_stats = avg_df[available_metrics].describe()\n",
        "            logging.info(\"\\nDescriptive statistics:\")\n",
        "            for stat, values in summary_stats.iterrows():\n",
        "                logging.info(f\"  {stat}: {values.to_dict()}\")\n",
        "        else:\n",
        "            logging.warning(\"No metrics available for summary statistics\")\n",
        "\n",
        "        # Generate specific average metrics requested\n",
        "        logging.info(\"\\n===== Average ipTM for binders to both ubiquitins =====\")\n",
        "        if 'avg_binder_ub_iptm' in avg_df.columns:\n",
        "            # Filter out NaN values\n",
        "            valid_data = avg_df.dropna(subset=['avg_binder_ub_iptm'])\n",
        "            if not valid_data.empty:\n",
        "                avg_value = valid_data['avg_binder_ub_iptm'].mean()\n",
        "                logging.info(f\"Overall average binder-Ub ipTM: {avg_value:.4f}\")\n",
        "                logging.info(f\"Number of valid data points: {len(valid_data)}/{len(avg_df)}\")\n",
        "\n",
        "                # Get top 10 binders by avg_binder_ub_iptm\n",
        "                top_binders = valid_data.sort_values('avg_binder_ub_iptm', ascending=False).head(10)\n",
        "                logging.info(\"\\nTop 10 binders by average interaction with both ubiquitins:\")\n",
        "                for idx, row in top_binders.iterrows():\n",
        "                    logging.info(f\"  Fold {row['fold_id']} ({row['model_type']}): {row['avg_binder_ub_iptm']:.4f}\")\n",
        "            else:\n",
        "                logging.warning(\"No valid binder-Ub ipTM data available\")\n",
        "        else:\n",
        "            logging.warning(\"No binder-Ub ipTM data available\")\n",
        "\n",
        "        # Generate a list of the top performing binders (overall ipTM and binder-Ub interaction)\n",
        "        logging.info(\"\\n===== Overall Best Binders =====\")\n",
        "        # Create a composite score that weights both overall ipTM and binder-Ub interaction\n",
        "        if 'avg_iptm' in avg_df.columns and 'avg_binder_ub_iptm' in avg_df.columns:\n",
        "            # Filter to rows with both metrics available\n",
        "            valid_data = avg_df.dropna(subset=['avg_iptm', 'avg_binder_ub_iptm'])\n",
        "\n",
        "            if not valid_data.empty:\n",
        "                # Calculate composite score\n",
        "                valid_data['composite_score'] = (valid_data['avg_iptm'] + valid_data['avg_binder_ub_iptm']) / 2\n",
        "                logging.info(\"Calculated composite score as (avg_iptm + avg_binder_ub_iptm) / 2\")\n",
        "\n",
        "                top_overall = valid_data.sort_values('composite_score', ascending=False).head(10)\n",
        "                logging.info(\"\\nTop 10 binders by composite score (overall ipTM + binder-Ub interaction):\")\n",
        "                for idx, row in top_overall.iterrows():\n",
        "                    logging.info(f\"  Fold {row['fold_id']} ({row['model_type']}): \" +\n",
        "                                 f\"composite={row['composite_score']:.4f}, \" +\n",
        "                                 f\"ipTM={row['avg_iptm']:.4f}, \" +\n",
        "                                 f\"binder-Ub={row['avg_binder_ub_iptm']:.4f}\")\n",
        "            else:\n",
        "                logging.warning(\"No valid data available for composite scoring\")\n",
        "        else:\n",
        "            logging.warning(\"Required metrics not available for composite scoring\")\n",
        "\n",
        "        # Add metric calculation explanations to the log\n",
        "        logging.info(\"\\n===== Metric Calculation Details =====\")\n",
        "        logging.info(\"1. iptm - Interface predicted TM-score from AlphaFold3 JSON\")\n",
        "        logging.info(\"2. binder_ub1_iptm - Interface ipTM between binder (chain A) and first ubiquitin (chain B)\")\n",
        "        logging.info(\"3. binder_ub2_iptm - Interface ipTM between binder (chain A) and second ubiquitin (chain C)\")\n",
        "        logging.info(\"4. binder_ub_iptm - Average of binder_ub1_iptm and binder_ub2_iptm\")\n",
        "        logging.info(\"5. binder_avg_plddt - Average pLDDT (per-residue confidence) for the binder (chain A)\")\n",
        "        logging.info(\"   Calculation: Average of B-factor values from PDB file, first averaged per residue then per chain\")\n",
        "        logging.info(\"6. composite_score - Average of avg_iptm and avg_binder_ub_iptm\")\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error in calculating or visualizing averages: {e}\")\n",
        "        import traceback\n",
        "        logging.error(traceback.format_exc())\n",
        "        avg_df = None\n",
        "\n",
        "    logging.info(\"\\nAnalysis complete!\")\n",
        "    logging.info(f\"Log file saved to: {log_file}\")\n",
        "\n",
        "    return df, avg_df, log_file\n",
        "\n",
        "# This can be run in Google Colab\n",
        "if __name__ == \"__main__\":\n",
        "    try:\n",
        "        # Mount Google Drive\n",
        "        drive.mount('/content/drive')\n",
        "\n",
        "        # Run the main analysis\n",
        "        df, avg_df, log_file = main()\n",
        "\n",
        "        # Display the first few rows of the averaged DataFrame if available\n",
        "        if avg_df is not None and not avg_df.empty:\n",
        "            print(\"\\nPreview of averaged results:\")\n",
        "            display(avg_df.head())\n",
        "        else:\n",
        "            print(\"\\nNo averaged results available to display\")\n",
        "\n",
        "        print(f\"\\nDetailed log saved to: {log_file}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error in main execution: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()# Install required packages\n",
        "!pip install -q biopython pandas numpy matplotlib seaborn\n",
        "\n",
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from Bio import PDB\n",
        "from google.colab import drive\n",
        "import glob\n",
        "import re\n",
        "import datetime\n",
        "import logging\n",
        "\n",
        "# Set up logging\n",
        "def setup_logging(output_dir):\n",
        "    \"\"\"Set up detailed logging for the analysis process\"\"\"\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    log_file = os.path.join(output_dir, f'af3_analysis_log_{datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.txt')\n",
        "\n",
        "    # Configure logging\n",
        "    logging.basicConfig(\n",
        "        level=logging.INFO,\n",
        "        format='%(asctime)s - %(levelname)s - %(message)s',\n",
        "        handlers=[\n",
        "            logging.FileHandler(log_file),\n",
        "            logging.StreamHandler()  # Also output to console\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    logging.info(\"=\" * 80)\n",
        "    logging.info(\"AlphaFold3 K11-Ub2 Binder Analysis Log\")\n",
        "    logging.info(\"=\" * 80)\n",
        "    logging.info(f\"Analysis started at: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "\n",
        "    return log_file\n",
        "\n",
        "def analyze_confidence_json(json_file):\n",
        "    \"\"\"\n",
        "    Analyze AlphaFold3 JSON confidence files and extract key metrics.\n",
        "    \"\"\"\n",
        "    logging.info(f\"Processing JSON file: {os.path.basename(json_file)}\")\n",
        "\n",
        "    try:\n",
        "        with open(json_file, 'r') as f:\n",
        "            data = json.load(f)\n",
        "\n",
        "        # Extract the base name from the file path\n",
        "        base_name = os.path.basename(json_file)\n",
        "\n",
        "        # Initialize default values\n",
        "        fold_id = \"unknown\"\n",
        "        model_type = \"unknown\"\n",
        "        model_num = \"0\"\n",
        "\n",
        "        # Try to extract fold_id (numeric part after \"fold_\")\n",
        "        fold_match = re.search(r'fold_(\\d+)', base_name)\n",
        "        if fold_match:\n",
        "            fold_id = fold_match.group(1)\n",
        "            logging.info(f\"  Extracted fold_id: {fold_id}\")\n",
        "        else:\n",
        "            # Try alternative patterns\n",
        "            parts = base_name.split('_')\n",
        "            if parts and parts[0].isdigit():\n",
        "                fold_id = parts[0]\n",
        "                logging.info(f\"  Extracted fold_id from filename start: {fold_id}\")\n",
        "\n",
        "        # Try to extract model_type (mpnnX or other identifier)\n",
        "        if \"fold_\" in base_name:\n",
        "            model_match = re.search(r'fold_\\d+_([^_]+)', base_name)\n",
        "            if model_match:\n",
        "                model_type = model_match.group(1)\n",
        "                logging.info(f\"  Extracted model_type: {model_type}\")\n",
        "        elif len(base_name.split('_')) > 1:\n",
        "            model_type = base_name.split('_')[1]\n",
        "            logging.info(f\"  Extracted model_type from second part: {model_type}\")\n",
        "\n",
        "        # Extract model number (last digit before .json)\n",
        "        model_num_match = re.search(r'confidences_(\\d+)\\.json$', base_name)\n",
        "        if model_num_match:\n",
        "            model_num = model_num_match.group(1)\n",
        "            logging.info(f\"  Extracted model_num: {model_num}\")\n",
        "        else:\n",
        "            alt_match = re.search(r'_(\\d+)\\.json$', base_name)\n",
        "            if alt_match:\n",
        "                model_num = alt_match.group(1)\n",
        "                logging.info(f\"  Extracted model_num from alternative pattern: {model_num}\")\n",
        "\n",
        "        # Extract key metrics\n",
        "        logging.info(\"  Extracting metrics from JSON data...\")\n",
        "\n",
        "        # Core metrics\n",
        "        results = {\n",
        "            'fold_id': fold_id,\n",
        "            'model_type': model_type,\n",
        "            'model_num': model_num,\n",
        "            'iptm': data.get('iptm', None),\n",
        "            'ptm': data.get('ptm', None),\n",
        "            'ranking_score': data.get('ranking_score', None),\n",
        "            'has_clash': data.get('has_clash', None),\n",
        "            'fraction_disordered': data.get('fraction_disordered', None),\n",
        "        }\n",
        "\n",
        "        logging.info(f\"  Core metrics - ipTM: {results['iptm']}, pTM: {results['ptm']}, ranking_score: {results['ranking_score']}\")\n",
        "\n",
        "        # Extract chain-specific metrics\n",
        "        chain_ptm = data.get('chain_ptm', [])\n",
        "        if len(chain_ptm) >= 3:\n",
        "            results['binder_ptm'] = chain_ptm[0]  # Chain A (binder)\n",
        "            results['ub1_ptm'] = chain_ptm[1]     # Chain B (first ubiquitin)\n",
        "            results['ub2_ptm'] = chain_ptm[2]     # Chain C (second ubiquitin)\n",
        "            logging.info(f\"  Chain-specific pTM - Binder: {chain_ptm[0]}, Ub1: {chain_ptm[1]}, Ub2: {chain_ptm[2]}\")\n",
        "        else:\n",
        "            logging.warning(f\"  chain_ptm data incomplete or missing: {chain_ptm}\")\n",
        "\n",
        "        # Extract interaction metrics between binder and ubiquitins\n",
        "        chain_pair_iptm = data.get('chain_pair_iptm', [])\n",
        "        if len(chain_pair_iptm) >= 3 and len(chain_pair_iptm[0]) >= 3:\n",
        "            # A-B interaction (binder to first Ub)\n",
        "            results['binder_ub1_iptm'] = chain_pair_iptm[0][1]\n",
        "            # A-C interaction (binder to second Ub)\n",
        "            results['binder_ub2_iptm'] = chain_pair_iptm[0][2]\n",
        "            # B-C interaction (between ubiquitins)\n",
        "            results['ub1_ub2_iptm'] = chain_pair_iptm[1][2]\n",
        "\n",
        "            logging.info(f\"  Chain interaction ipTM - Binder-Ub1: {chain_pair_iptm[0][1]}, Binder-Ub2: {chain_pair_iptm[0][2]}, Ub1-Ub2: {chain_pair_iptm[1][2]}\")\n",
        "        else:\n",
        "            logging.warning(f\"  chain_pair_iptm data incomplete or missing: {chain_pair_iptm}\")\n",
        "\n",
        "        # Extract PAE information\n",
        "        chain_pair_pae_min = data.get('chain_pair_pae_min', [])\n",
        "        if len(chain_pair_pae_min) >= 3 and len(chain_pair_pae_min[0]) >= 3:\n",
        "            # A-B interaction (binder to first Ub)\n",
        "            results['binder_ub1_pae_min'] = chain_pair_pae_min[0][1]\n",
        "            # A-C interaction (binder to second Ub)\n",
        "            results['binder_ub2_pae_min'] = chain_pair_pae_min[0][2]\n",
        "            # B-C interaction (between ubiquitins)\n",
        "            results['ub1_ub2_pae_min'] = chain_pair_pae_min[1][2]\n",
        "\n",
        "            logging.info(f\"  Chain interaction PAE min - Binder-Ub1: {chain_pair_pae_min[0][1]}, Binder-Ub2: {chain_pair_pae_min[0][2]}, Ub1-Ub2: {chain_pair_pae_min[1][2]}\")\n",
        "        else:\n",
        "            logging.warning(f\"  chain_pair_pae_min data incomplete or missing: {chain_pair_pae_min}\")\n",
        "\n",
        "        return results\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error processing JSON file {json_file}: {e}\")\n",
        "        # Return minimal information to avoid breaking the pipeline\n",
        "        return {\n",
        "            'fold_id': os.path.basename(json_file).split('_')[1] if '_' in os.path.basename(json_file) else \"error\",\n",
        "            'model_type': \"error\",\n",
        "            'model_num': \"error\",\n",
        "            'error_message': str(e)\n",
        "        }\n",
        "\n",
        "def calculate_plddt_from_pdb(pdb_file):\n",
        "    \"\"\"\n",
        "    Calculate the average pLDDT for each chain from PDB/CIF file.\n",
        "    \"\"\"\n",
        "    logging.info(f\"Calculating pLDDT from {os.path.basename(pdb_file)}\")\n",
        "\n",
        "    try:\n",
        "        # Read the file content\n",
        "        with open(pdb_file, 'r') as f:\n",
        "            content = f.read()\n",
        "\n",
        "        # Extract atom lines\n",
        "        atomLines = [line for line in content.split('\\n') if line.startswith('ATOM')]\n",
        "\n",
        "        if not atomLines:\n",
        "            logging.warning(f\"No ATOM lines found in {pdb_file}\")\n",
        "            return {}\n",
        "\n",
        "        logging.info(f\"  Found {len(atomLines)} ATOM lines\")\n",
        "\n",
        "        # Parse atom data based on the AlphaFold3 mmCIF-like format\n",
        "        # Format example: ATOM 1    N N   . GLY A 1 1   ? -14.504 -13.150 -32.624 1.00 59.06 1   A 1\n",
        "        atomData = []\n",
        "        for line in atomLines:\n",
        "            parts = [p for p in line.split() if p]\n",
        "\n",
        "            if len(parts) < 15:\n",
        "                continue\n",
        "\n",
        "            try:\n",
        "                atomData.append({\n",
        "                    'atomType': parts[2],\n",
        "                    'residueType': parts[5],\n",
        "                    'chainId': parts[6],\n",
        "                    'residueNum': int(parts[8]),\n",
        "                    'bFactor': float(parts[14])\n",
        "                })\n",
        "            except (ValueError, IndexError) as e:\n",
        "                logging.warning(f\"  Error parsing line: {line}, error: {e}\")\n",
        "                continue\n",
        "\n",
        "        logging.info(f\"  Successfully parsed {len(atomData)} atoms\")\n",
        "\n",
        "        # Group by chain\n",
        "        chainData = {}\n",
        "        for atom in atomData:\n",
        "            chainId = atom['chainId']\n",
        "            if chainId not in chainData:\n",
        "                chainData[chainId] = []\n",
        "            chainData[chainId].append(atom)\n",
        "\n",
        "        logging.info(f\"  Found chains: {list(chainData.keys())}\")\n",
        "\n",
        "        # Calculate per-chain average pLDDT\n",
        "        results = {}\n",
        "\n",
        "        for chainId, atoms in chainData.items():\n",
        "            # Group by residue\n",
        "            residueGroups = {}\n",
        "            for atom in atoms:\n",
        "                residueNum = atom['residueNum']\n",
        "                if residueNum not in residueGroups:\n",
        "                    residueGroups[residueNum] = []\n",
        "                residueGroups[residueNum].append(atom['bFactor'])\n",
        "\n",
        "            num_residues = len(residueGroups)\n",
        "            logging.info(f\"  Chain {chainId}: {len(atoms)} atoms in {num_residues} residues\")\n",
        "\n",
        "            # Calculate per-residue averages\n",
        "            residueAvgs = [sum(bFactors)/len(bFactors) for bFactors in residueGroups.values()]\n",
        "\n",
        "            # Calculate chain average (average of residue averages)\n",
        "            if residueAvgs:\n",
        "                chainAvg = sum(residueAvgs) / len(residueAvgs)\n",
        "\n",
        "                # Map chain IDs to our standard names\n",
        "                if chainId == 'A':\n",
        "                    results['binder_avg_plddt'] = chainAvg\n",
        "                    logging.info(f\"  Binder (Chain A) average pLDDT: {chainAvg:.2f}\")\n",
        "                elif chainId == 'B':\n",
        "                    results['ub1_avg_plddt'] = chainAvg\n",
        "                    logging.info(f\"  Ub1 (Chain B) average pLDDT: {chainAvg:.2f}\")\n",
        "                elif chainId == 'C':\n",
        "                    results['ub2_avg_plddt'] = chainAvg\n",
        "                    logging.info(f\"  Ub2 (Chain C) average pLDDT: {chainAvg:.2f}\")\n",
        "\n",
        "        return results\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error processing {pdb_file}: {e}\")\n",
        "        return {}\n",
        "\n",
        "def match_pdb_to_json(json_file, pdb_dir):\n",
        "    \"\"\"\n",
        "    Find the corresponding PDB/CIF file for a given JSON confidence file.\n",
        "    \"\"\"\n",
        "    base_name = os.path.basename(json_file)\n",
        "    logging.info(f\"Finding matching PDB/CIF file for {base_name}\")\n",
        "\n",
        "    # Try to extract model number from the JSON filename\n",
        "    model_num = None\n",
        "    model_match = re.search(r'confidences_(\\d+)', base_name)\n",
        "    if model_match:\n",
        "        model_num = model_match.group(1)\n",
        "        logging.info(f\"  Extracted model number: {model_num}\")\n",
        "    else:\n",
        "        # Try alternative pattern\n",
        "        alt_match = re.search(r'_(\\d+)\\.json$', base_name)\n",
        "        if alt_match:\n",
        "            model_num = alt_match.group(1)\n",
        "            logging.info(f\"  Extracted model number (alt pattern): {model_num}\")\n",
        "\n",
        "    # Try to extract the fold ID\n",
        "    fold_id = None\n",
        "    fold_match = re.search(r'fold_(\\d+)', base_name)\n",
        "    if fold_match:\n",
        "        fold_id = fold_match.group(1)\n",
        "        logging.info(f\"  Extracted fold ID: {fold_id}\")\n",
        "    elif base_name.split('_')[0].isdigit():\n",
        "        fold_id = base_name.split('_')[0]\n",
        "        logging.info(f\"  Extracted fold ID from filename start: {fold_id}\")\n",
        "\n",
        "    # If we have fold_id, try to find a matching PDB file\n",
        "    if fold_id:\n",
        "        # Generate patterns from most specific to most general\n",
        "        patterns = []\n",
        "\n",
        "        # If we have a model number, try patterns with it first\n",
        "        if model_num:\n",
        "            patterns.append(f\"*{fold_id}*_model_{model_num}.cif\")\n",
        "            patterns.append(f\"*{fold_id}*model_{model_num}*.cif\")\n",
        "\n",
        "        # Add more general patterns\n",
        "        patterns.append(f\"*{fold_id}*_model_*.cif\")\n",
        "        patterns.append(f\"*{fold_id}*model_*.cif\")\n",
        "        patterns.append(f\"*{fold_id}*.cif\")\n",
        "\n",
        "        # Try each pattern\n",
        "        for pattern in patterns:\n",
        "            logging.info(f\"  Trying pattern: {pattern}\")\n",
        "            matching_pdbs = glob.glob(os.path.join(pdb_dir, pattern))\n",
        "\n",
        "            if matching_pdbs:\n",
        "                logging.info(f\"  Found {len(matching_pdbs)} matching files\")\n",
        "\n",
        "                # If multiple matches, try to find the best one\n",
        "                if len(matching_pdbs) > 1 and model_num:\n",
        "                    for pdb_file in matching_pdbs:\n",
        "                        if f\"model_{model_num}\" in pdb_file:\n",
        "                            logging.info(f\"  Best match: {os.path.basename(pdb_file)}\")\n",
        "                            return pdb_file\n",
        "\n",
        "                logging.info(f\"  Selected match: {os.path.basename(matching_pdbs[0])}\")\n",
        "                return matching_pdbs[0]\n",
        "            else:\n",
        "                logging.info(f\"  No matches for pattern: {pattern}\")\n",
        "\n",
        "    # If we get here, no matching PDB was found\n",
        "    logging.warning(f\"No matching PDB/CIF file found for {base_name}\")\n",
        "    return None\n",
        "\n",
        "def process_folder(base_dir):\n",
        "    \"\"\"\n",
        "    Process all JSON confidence files in a directory and its subdirectories.\n",
        "    \"\"\"\n",
        "    logging.info(f\"Processing folder: {base_dir}\")\n",
        "\n",
        "    # Find all JSON confidence files\n",
        "    json_files = glob.glob(os.path.join(base_dir, \"**\", \"*summary_confidences_*.json\"), recursive=True)\n",
        "\n",
        "    if not json_files:\n",
        "        logging.warning(f\"No JSON confidence files found in {base_dir}\")\n",
        "        # Try a more general pattern\n",
        "        json_files = glob.glob(os.path.join(base_dir, \"**\", \"*.json\"), recursive=True)\n",
        "        if json_files:\n",
        "            logging.info(f\"Found {len(json_files)} JSON files with general pattern\")\n",
        "\n",
        "    all_results = []\n",
        "    processed_count = 0\n",
        "    total_files = len(json_files)\n",
        "\n",
        "    logging.info(f\"Found {total_files} JSON files to process\")\n",
        "\n",
        "    for json_file in json_files:\n",
        "        processed_count += 1\n",
        "        if processed_count % 10 == 0 or processed_count == 1 or processed_count == total_files:\n",
        "            logging.info(f\"Processing file {processed_count}/{total_files}: {os.path.basename(json_file)}\")\n",
        "\n",
        "        # Process the JSON file\n",
        "        json_results = analyze_confidence_json(json_file)\n",
        "\n",
        "        # Try to find matching PDB/CIF file\n",
        "        pdb_dir = os.path.dirname(json_file)\n",
        "        pdb_file = match_pdb_to_json(json_file, pdb_dir)\n",
        "\n",
        "        if pdb_file:\n",
        "            # Calculate pLDDT values\n",
        "            plddt_results = calculate_plddt_from_pdb(pdb_file)\n",
        "            # Merge with JSON results\n",
        "            json_results.update(plddt_results)\n",
        "        else:\n",
        "            logging.warning(f\"  No matching PDB file found for {os.path.basename(json_file)}\")\n",
        "\n",
        "        all_results.append(json_results)\n",
        "\n",
        "    # Convert to DataFrame\n",
        "    df = pd.DataFrame(all_results)\n",
        "    logging.info(f\"Created DataFrame with {len(df)} rows and {len(df.columns)} columns\")\n",
        "\n",
        "    # Log column information\n",
        "    logging.info(f\"Columns in DataFrame: {list(df.columns)}\")\n",
        "\n",
        "    # Check for missing values in key columns\n",
        "    for col in ['iptm', 'binder_ub1_iptm', 'binder_ub2_iptm', 'binder_avg_plddt']:\n",
        "        if col in df.columns:\n",
        "            null_count = df[col].isna().sum()\n",
        "            logging.info(f\"Column '{col}': {len(df) - null_count} non-null values, {null_count} null values\")\n",
        "\n",
        "    return df\n",
        "\n",
        "def calculate_model_averages(df):\n",
        "    \"\"\"\n",
        "    Calculate averages across the models for each fold_id/model_type combination.\n",
        "    \"\"\"\n",
        "    logging.info(\"Calculating model averages\")\n",
        "\n",
        "    # Make sure we have the required columns\n",
        "    required_cols = ['fold_id', 'model_type', 'model_num']\n",
        "    for col in required_cols:\n",
        "        if col not in df.columns:\n",
        "            logging.error(f\"Required column '{col}' not found in data\")\n",
        "            return pd.DataFrame()  # Return empty dataframe\n",
        "\n",
        "    # Count unique fold_id and model_type combinations\n",
        "    unique_combinations = df.groupby(['fold_id', 'model_type']).size().reset_index(name='model_count')\n",
        "    logging.info(f\"Found {len(unique_combinations)} unique fold_id/model_type combinations\")\n",
        "\n",
        "    # Make sure model_num is a string\n",
        "    df['model_num'] = df['model_num'].astype(str)\n",
        "\n",
        "    # Group by fold_id and model_type\n",
        "    grouped = df.groupby(['fold_id', 'model_type'])\n",
        "\n",
        "    avg_results = []\n",
        "\n",
        "    # Track models that don't have all 5 models (0-4)\n",
        "    incomplete_models = []\n",
        "\n",
        "    logging.info(\"Processing each fold_id/model_type group...\")\n",
        "\n",
        "    for i, ((fold_id, model_type), group) in enumerate(grouped):\n",
        "        logging.info(f\"Processing group {i+1}/{len(unique_combinations)}: {fold_id}/{model_type}\")\n",
        "\n",
        "        # Get all model numbers for this group\n",
        "        model_nums = sorted(group['model_num'].unique())\n",
        "        logging.info(f\"  Models in group: {', '.join(model_nums)}\")\n",
        "\n",
        "        # Check if we have all 5 models (0-4)\n",
        "        expected_models = ['0', '1', '2', '3', '4']\n",
        "        missing_models = [m for m in expected_models if m not in model_nums]\n",
        "\n",
        "        if missing_models:\n",
        "            logging.warning(f\"  Missing models: {', '.join(missing_models)}\")\n",
        "            incomplete_models.append((fold_id, model_type, missing_models))\n",
        "\n",
        "        # Calculate interface metric between binder and both ubiquitins\n",
        "        if 'binder_ub1_iptm' in group.columns and 'binder_ub2_iptm' in group.columns:\n",
        "            group['binder_ub_iptm'] = (group['binder_ub1_iptm'] + group['binder_ub2_iptm']) / 2\n",
        "            logging.info(\"  Calculated binder_ub_iptm as average of binder_ub1_iptm and binder_ub2_iptm\")\n",
        "\n",
        "        # List of metrics to average\n",
        "        metrics_to_avg = [\n",
        "            # Overall metrics\n",
        "            'iptm', 'ptm', 'ranking_score', 'has_clash', 'fraction_disordered',\n",
        "\n",
        "            # Chain-specific metrics\n",
        "            'binder_ptm', 'ub1_ptm', 'ub2_ptm',\n",
        "\n",
        "            # Interface metrics\n",
        "            'binder_ub1_iptm', 'binder_ub2_iptm', 'binder_ub_iptm', 'ub1_ub2_iptm',\n",
        "\n",
        "            # pLDDT metrics\n",
        "            'binder_avg_plddt', 'ub1_avg_plddt', 'ub2_avg_plddt',\n",
        "\n",
        "            # PAE metrics\n",
        "            'binder_ub1_pae_min', 'binder_ub2_pae_min', 'ub1_ub2_pae_min'\n",
        "        ]\n",
        "\n",
        "        # Initialize the result dictionary\n",
        "        avg_data = {\n",
        "            'fold_id': fold_id,\n",
        "            'model_type': model_type,\n",
        "            'num_models': len(group),\n",
        "            'model_nums': ','.join(model_nums)\n",
        "        }\n",
        "\n",
        "        # Calculate average for each metric if it exists\n",
        "        logging.info(\"  Calculating averages for metrics:\")\n",
        "\n",
        "        for metric in metrics_to_avg:\n",
        "            if metric in group.columns:\n",
        "                # Skip metrics with all NaN values\n",
        "                if group[metric].isna().all():\n",
        "                    logging.warning(f\"    Metric '{metric}' has all NaN values\")\n",
        "                    avg_data[f'avg_{metric}'] = None\n",
        "                    continue\n",
        "\n",
        "                # Count non-null values\n",
        "                non_null_count = group[metric].count()\n",
        "                if non_null_count < len(group):\n",
        "                    logging.warning(f\"    Metric '{metric}' has {non_null_count}/{len(group)} non-null values\")\n",
        "\n",
        "                # Special handling for boolean-like metrics\n",
        "                if metric == 'has_clash' or metric == 'fraction_disordered':\n",
        "                    avg_value = group[metric].mean() > 0.5\n",
        "                    avg_data[f'avg_{metric}'] = avg_value\n",
        "                    logging.info(f\"    {metric}: {avg_value} (boolean conversion)\")\n",
        "                else:\n",
        "                    # Regular numeric average\n",
        "                    avg_value = group[metric].mean()\n",
        "                    avg_data[f'avg_{metric}'] = avg_value\n",
        "                    logging.info(f\"    {metric}: {avg_value:.4f}\")\n",
        "\n",
        "        # Find the best model in this group based on ranking score or ipTM\n",
        "        if 'ranking_score' in group.columns and not group['ranking_score'].isna().all():\n",
        "            best_idx = group['ranking_score'].idxmax()\n",
        "            best_model = group.loc[best_idx, 'model_num']\n",
        "            avg_data['best_model_num'] = best_model\n",
        "            logging.info(f\"  Best model by ranking_score: {best_model}\")\n",
        "\n",
        "            # Add best model metrics\n",
        "            for metric in ['iptm', 'ranking_score', 'binder_ub_iptm']:\n",
        "                if metric in group.columns and best_idx in group.index and not pd.isna(group.loc[best_idx, metric]):\n",
        "                    avg_data[f'best_model_{metric}'] = group.loc[best_idx, metric]\n",
        "                    logging.info(f\"    best_model_{metric}: {group.loc[best_idx, metric]:.4f}\")\n",
        "        elif 'iptm' in group.columns and not group['iptm'].isna().all():\n",
        "            best_idx = group['iptm'].idxmax()\n",
        "            best_model = group.loc[best_idx, 'model_num']\n",
        "            avg_data['best_model_num'] = best_model\n",
        "            logging.info(f\"  Best model by iptm: {best_model}\")\n",
        "\n",
        "            # Add best model metrics\n",
        "            for metric in ['iptm', 'binder_ub_iptm']:\n",
        "                if metric in group.columns and best_idx in group.index and not pd.isna(group.loc[best_idx, metric]):\n",
        "                    avg_data[f'best_model_{metric}'] = group.loc[best_idx, metric]\n",
        "                    logging.info(f\"    best_model_{metric}: {group.loc[best_idx, metric]:.4f}\")\n",
        "\n",
        "        avg_results.append(avg_data)\n",
        "\n",
        "    # Convert to DataFrame\n",
        "    avg_df = pd.DataFrame(avg_results)\n",
        "    logging.info(f\"Created averages DataFrame with {len(avg_df)} rows and {len(avg_df.columns)} columns\")\n",
        "\n",
        "    # Report on missing models\n",
        "    if incomplete_models:\n",
        "        total_incomplete = len(incomplete_models)\n",
        "        logging.warning(f\"\\nFound {total_incomplete} fold_id/model_type combinations with missing models\")\n",
        "        logging.warning(\"Top 5 incomplete models:\")\n",
        "        for i, (fold_id, model_type, missing) in enumerate(incomplete_models[:5]):\n",
        "            logging.warning(f\"  {fold_id} {model_type}: Missing models {', '.join(missing)}\")\n",
        "\n",
        "        if total_incomplete > 5:\n",
        "            logging.warning(f\"  ...and {total_incomplete - 5} more\")\n",
        "\n",
        "    # Log column information\n",
        "    logging.info(f\"Columns in averages DataFrame: {list(avg_df.columns)}\")\n",
        "\n",
        "    return avg_df\n",
        "\n",
        "def generate_visualizations(df, avg_df, output_dir):\n",
        "    \"\"\"\n",
        "    Generate visualizations for binder quality and interactions\n",
        "    \"\"\"\n",
        "    logging.info(\"Generating visualizations\")\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # Focus on just the two main visualizations:\n",
        "    # 1. Binder Quality vs Binding Interface Quality\n",
        "    if all(col in avg_df.columns for col in ['avg_binder_plddt', 'avg_binder_ub_iptm']):\n",
        "        # Filter for valid data\n",
        "        valid_data = avg_df.dropna(subset=['avg_binder_plddt', 'avg_binder_ub_iptm'])\n",
        "\n",
        "        logging.info(f\"Plotting Binder Quality vs Binding Interface Quality: {len(valid_data)}/{len(avg_df)} data points\")\n",
        "\n",
        "        if valid_data.shape[0] >= 2:\n",
        "            plt.figure(figsize=(12, 10))\n",
        "\n",
        "            # Log any rows with missing values\n",
        "            missing_data = avg_df[avg_df['avg_binder_plddt'].isna() | avg_df['avg_binder_ub_iptm'].isna()]\n",
        "            if not missing_data.empty:\n",
        "                logging.warning(f\"Found {len(missing_data)} rows with missing values for quality plot:\")\n",
        "                for idx, row in missing_data.iterrows():\n",
        "                    logging.warning(f\"  {row['fold_id']} {row['model_type']}: \" +\n",
        "                                    f\"pLDDT={row.get('avg_binder_plddt', 'N/A')}, \" +\n",
        "                                    f\"ipTM={row.get('avg_binder_ub_iptm', 'N/A')}\")\n",
        "\n",
        "            # Determine color values\n",
        "            color_values = valid_data['avg_ranking_score'] if 'avg_ranking_score' in valid_data.columns else None\n",
        "\n",
        "            logging.info(\"Creating scatter plot\")\n",
        "            scatter = plt.scatter(\n",
        "                valid_data['avg_binder_plddt'],\n",
        "                valid_data['avg_binder_ub_iptm'],\n",
        "                c=color_values,\n",
        "                cmap='viridis',\n",
        "                alpha=0.9,\n",
        "                s=100,\n",
        "                edgecolors='black',\n",
        "                linewidths=0.5\n",
        "            )\n",
        "\n",
        "            if color_values is not None:\n",
        "                plt.colorbar(scatter, label='Average Ranking Score')\n",
        "\n",
        "            plt.title('Binder Quality vs Binding Interface Quality', fontsize=16)\n",
        "            plt.xlabel('Average Binder pLDDT', fontsize=14)\n",
        "            plt.ylabel('Average Binder-Ub Interface ipTM', fontsize=14)\n",
        "            plt.grid(alpha=0.3)\n",
        "\n",
        "            # Add fold_id annotations with better positioning and visibility\n",
        "            for i, row in valid_data.iterrows():\n",
        "                plt.annotate(\n",
        "                    row['fold_id'],\n",
        "                    (row['avg_binder_plddt'], row['avg_binder_ub_iptm']),\n",
        "                    fontsize=9,\n",
        "                    xytext=(5, 5),  # Small offset from point\n",
        "                    textcoords='offset points',\n",
        "                    fontweight='bold',\n",
        "                    bbox=dict(boxstyle=\"round,pad=0.3\", fc=\"white\", alpha=0.7, ec=\"none\")\n",
        "                )\n",
        "\n",
        "            # Save both regular and high-res versions\n",
        "            plt.tight_layout()\n",
        "            plot_path = os.path.join(output_dir, 'binder_quality_vs_interface.png')\n",
        "            plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
        "            logging.info(f\"Saved plot to {plot_path}\")\n",
        "            plt.close()\n",
        "\n",
        "    # 2. Binder interaction with Ub1 vs Ub2\n",
        "    if all(col in avg_df.columns for col in ['avg_binder_ub1_iptm', 'avg_binder_ub2_iptm']):\n",
        "        # Filter for valid data\n",
        "        valid_data = avg_df.dropna(subset=['avg_binder_ub1_iptm', 'avg_binder_ub2_iptm'])\n",
        "\n",
        "        logging.info(f\"Plotting Binder Interaction with Ub1 vs Ub2: {len(valid_data)}/{len(avg_df)} data points\")\n",
        "\n",
        "        if valid_data.shape[0] >= 2:\n",
        "            plt.figure(figsize=(10, 8))\n",
        "\n",
        "            # Determine color values\n",
        "            color_values = valid_data['avg_iptm'] if 'avg_iptm' in valid_data.columns else None\n",
        "\n",
        "            logging.info(\"Creating scatter plot for Ub1 vs Ub2 interaction\")\n",
        "            scatter = plt.scatter(\n",
        "                valid_data['avg_binder_ub1_iptm'],\n",
        "                valid_data['avg_binder_ub2_iptm'],\n",
        "                c=color_values,\n",
        "                cmap='viridis',\n",
        "                alpha=0.8,\n",
        "                s=80,\n",
        "                edgecolors='black',\n",
        "                linewidths=0.5\n",
        "            )\n",
        "\n",
        "            if color_values is not None:\n",
        "                plt.colorbar(scatter, label='Average Overall ipTM')\n",
        "\n",
        "            plt.title('Average Binder Interaction with Ub1 vs Ub2')\n",
        "            plt.xlabel('Avg Binder-Ub1 ipTM')\n",
        "            plt.ylabel('Avg Binder-Ub2 ipTM')\n",
        "            plt.grid(alpha=0.3)\n",
        "\n",
        "            # Add fold_id annotations with better visibility\n",
        "            for i, row in valid_data.iterrows():\n",
        "                plt.annotate(\n",
        "                    row['fold_id'],\n",
        "                    (row['avg_binder_ub1_iptm'], row['avg_binder_ub2_iptm']),\n",
        "                    fontsize=9,\n",
        "                    xytext=(5, 5),\n",
        "                    textcoords='offset points',\n",
        "                    bbox=dict(boxstyle=\"round,pad=0.3\", fc=\"white\", alpha=0.7)\n",
        "                )\n",
        "\n",
        "            plt.tight_layout()\n",
        "            plot_path = os.path.join(output_dir, 'binder_ub1_vs_ub2_interaction.png')\n",
        "            plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
        "            logging.info(f\"Saved plot to {plot_path}\")\n",
        "            plt.close()\n",
        "\n",
        "    logging.info(\"Visualization generation complete\")"
      ]
    }
  ]
}