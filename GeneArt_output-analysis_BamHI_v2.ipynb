{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1TBwTgjdVjvvvEwG47fPe6asXybidKpNW",
      "authorship_tag": "ABX9TyPJWt6Jb++Pl8kTaVLlPD2i",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eoinleen/Protein-design-random/blob/main/GeneArt_output-analysis_BamHI_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 729
        },
        "id": "2FDza5vs2QmQ",
        "outputId": "2efb2f1e-47ca-453c-cee1-c157899033db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing required packages...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
            "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
            "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Requirement already satisfied: biopython in /usr/local/lib/python3.11/dist-packages (1.85)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Requirement already satisfied: biopython in /usr/local/lib/python3.11/dist-packages (1.85)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from biopython) (1.26.4)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from biopython) (1.26.4)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Biopython successfully installed\n",
            "Mounting Google Drive...\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Google Drive mounted at /content/drive\n",
            "\n",
            "FASTA Processing Script for Google Colab\n",
            "\n",
            "Enter the path to the directory in Google Drive containing FASTA files (press Enter to use default: /content/drive/MyDrive/Fasta-files/GeneArt-summary-2025AAH3KF): \n",
            "\n",
            "Searching for FASTA files in: /content/drive/MyDrive/Fasta-files/GeneArt-summary-2025AAH3KF\n",
            "Found 21 FASTA files:\n",
            "  - /content/drive/MyDrive/Fasta-files/GeneArt-summary-2025AAH3KF/110287_mpnn3_model1_607599/110287_mpnn3_model1.fasta\n",
            "  - /content/drive/MyDrive/Fasta-files/GeneArt-summary-2025AAH3KF/150447_mpnn3_model2_607591/150447_mpnn3_model2.fasta\n",
            "  - /content/drive/MyDrive/Fasta-files/GeneArt-summary-2025AAH3KF/215645_mpnn10_model2_607588/215645_mpnn10_model2.fasta\n",
            "  - /content/drive/MyDrive/Fasta-files/GeneArt-summary-2025AAH3KF/21_607613/21.fasta\n",
            "  - /content/drive/MyDrive/Fasta-files/GeneArt-summary-2025AAH3KF/325188_mpnn2_model1_607598/325188_mpnn2_model1.fasta\n",
            "  ... and 16 more\n",
            "\n",
            "Created output directory: /content/drive/MyDrive/Fasta-files/GeneArt-summary-2025AAH3KF/GeneArt_analysis_output\n",
            "\n",
            "Compiling sequences with clean headers...\n",
            "Compiled 21 sequences saved to /content/drive/MyDrive/Fasta-files/GeneArt-summary-2025AAH3KF/GeneArt_analysis_output/compiled_sequences.fasta\n",
            "Detailed processing information saved to /content/drive/MyDrive/Fasta-files/GeneArt-summary-2025AAH3KF/GeneArt_analysis_output/processing_details.log\n",
            "\n",
            "Creating annotated HTML file...\n",
            "Annotated sequences saved to /content/drive/MyDrive/Fasta-files/GeneArt-summary-2025AAH3KF/GeneArt_analysis_output/annotated_sequences.html\n",
            "\n",
            "Translating sequences...\n",
            "Translated sequences saved to /content/drive/MyDrive/Fasta-files/GeneArt-summary-2025AAH3KF/GeneArt_analysis_output/translated_sequences.fasta\n",
            "\n",
            "Processing complete! All files saved to: /content/drive/MyDrive/Fasta-files/GeneArt-summary-2025AAH3KF/GeneArt_analysis_output\n",
            "You can access these files directly in your Google Drive.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/Bio/Seq.py:2879: BiopythonWarning: Partial codon, len(sequence) not a multiple of three. Explicitly trim the sequence or add trailing N before translation. This may become an error in future.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# FASTA PROCESSING AND ANALYSIS SCRIPT FOR GENEART DNA SEQUENCES\n",
        "# ============================================================================\n",
        "#\n",
        "# DESCRIPTION:\n",
        "#   This script processes DNA sequence files in FASTA format from GeneArt.\n",
        "#   It recursively finds all .fasta files in a directory structure, compiles\n",
        "#   them into a single file, analyzes restriction sites and stop codons,\n",
        "#   and translates the sequences starting at the BamHI site.\n",
        "#\n",
        "# FEATURES:\n",
        "#   - Finds all .fasta files in a directory and subdirectories\n",
        "#   - Combines all sequences into a single compiled FASTA file\n",
        "#   - Creates an HTML file with color-coded annotations for:\n",
        "#     * BamHI sites (GGATCC) - Red background\n",
        "#     * EcoRI sites (GAATTC) - Green background\n",
        "#     * HindIII sites (AAGCTT) - Blue background\n",
        "#     * In-frame stop codons (TAA, TAG, TGA) - Red, underlined text\n",
        "#     * In frame upstream start codon (ATG)\n",
        "#   - Translates DNA sequences starting from the BamHI site (including the site)\n",
        "#   - Outputs translated protein sequences in FASTA format\n",
        "#\n",
        "#\n",
        "# OUTPUT FILES:\n",
        "#   - compiled_sequences.fasta: All DNA sequences in one file\n",
        "#   - annotated_sequences.html: Interactive visualizations with highlighted features\n",
        "#   - translated_sequences.fasta: Protein translations starting at BamHI\n",
        "#   - procesing log file\n",
        "#\n",
        "# USAGE:\n",
        "#   Run this script in Google Colab with mounted Google Drive access.\n",
        "#   The script will prompt for the directory containing the FASTA files.\n",
        "#\n",
        "# AUTHOR:\n",
        "#   Created with Claude AI assistant, March 2025\n",
        "#\n",
        "# ============================================================================\n",
        "\n",
        "# First, install required packages\n",
        "print(\"Installing required packages...\")\n",
        "try:\n",
        "    import pip\n",
        "    pip.main(['install', 'biopython'])\n",
        "    print(\"Biopython successfully installed\")\n",
        "except:\n",
        "    # In case the above method doesn't work in the current Colab environment\n",
        "    print(\"Using alternative installation method...\")\n",
        "    !pip install biopython\n",
        "    print(\"Installation complete\")\n",
        "\n",
        "# Now import the required packages\n",
        "import os\n",
        "import re\n",
        "import glob\n",
        "from pathlib import Path\n",
        "import html\n",
        "from google.colab import drive\n",
        "\n",
        "# Import Biopython packages after installation\n",
        "from Bio import SeqIO\n",
        "from Bio.Seq import Seq\n",
        "from Bio.SeqRecord import SeqRecord\n",
        "\n",
        "# Mount Google Drive\n",
        "print(\"Mounting Google Drive...\")\n",
        "try:\n",
        "    drive.mount('/content/drive')\n",
        "    print(\"Google Drive mounted at /content/drive\")\n",
        "except:\n",
        "    print(\"Google Drive is already mounted or there was an issue mounting it.\")\n",
        "\n",
        "def find_fasta_files(directory):\n",
        "    \"\"\"\n",
        "    Find all FASTA files recursively in the given directory,\n",
        "    excluding any previously created output directories.\n",
        "    \"\"\"\n",
        "    # Define the output directory name to exclude\n",
        "    output_dir_name = \"GeneArt_analysis_output\"\n",
        "\n",
        "    # Find all FASTA files\n",
        "    all_files = []\n",
        "    for root, dirs, files in os.walk(directory):\n",
        "        # Skip the output directory if found\n",
        "        if output_dir_name in dirs:\n",
        "            dirs.remove(output_dir_name)  # Don't traverse into the output directory\n",
        "\n",
        "        # Add any FASTA files found in the current directory\n",
        "        for file in files:\n",
        "            if file.endswith('.fasta'):\n",
        "                all_files.append(os.path.join(root, file))\n",
        "\n",
        "    return all_files\n",
        "\n",
        "def compile_fasta_sequences(input_files, output_file, log_file):\n",
        "    \"\"\"Compile all FASTA sequences into a single file with clean headers.\"\"\"\n",
        "    all_records = []\n",
        "\n",
        "    # Create a log file with detailed information\n",
        "    with open(log_file, \"w\") as log:\n",
        "        log.write(\"# DNA Sequence Processing Log\\n\")\n",
        "        log.write(\"# This file contains detailed information about the sequences processed\\n\")\n",
        "        log.write(\"# The compiled FASTA files have simplified headers for clarity\\n\\n\")\n",
        "\n",
        "        for file_path in input_files:\n",
        "            # Get a more friendly sequence ID from the filename\n",
        "            file_name = os.path.basename(file_path)\n",
        "            seq_id = os.path.splitext(file_name)[0]\n",
        "\n",
        "            # Log the detailed information\n",
        "            log.write(f\"Sequence ID: {seq_id}\\n\")\n",
        "            log.write(f\"Source file: {file_path}\\n\")\n",
        "\n",
        "            for i, record in enumerate(SeqIO.parse(file_path, \"fasta\")):\n",
        "                # Log original record details\n",
        "                log.write(f\"  Original ID: {record.id}\\n\")\n",
        "                log.write(f\"  Original description: {record.description}\\n\")\n",
        "                log.write(f\"  Sequence length: {len(record.seq)} bp\\n\\n\")\n",
        "\n",
        "                # Create a new record with clean ID\n",
        "                new_record = SeqRecord(\n",
        "                    record.seq,\n",
        "                    id=seq_id,\n",
        "                    description=\"\"  # Empty description for clean header\n",
        "                )\n",
        "                all_records.append(new_record)\n",
        "\n",
        "    # Write all records to the output file with clean headers\n",
        "    with open(output_file, \"w\") as f:\n",
        "        for record in all_records:\n",
        "            f.write(f\">{record.id}\\n\")\n",
        "            # Write sequence with 60 characters per line (standard FASTA format)\n",
        "            seq_str = str(record.seq)\n",
        "            for i in range(0, len(seq_str), 60):\n",
        "                f.write(f\"{seq_str[i:i+60]}\\n\")\n",
        "\n",
        "    return all_records\n",
        "\n",
        "def analyze_dna_sequences(fasta_records, output_html):\n",
        "    \"\"\"\n",
        "    Analyze DNA sequences and create an annotated HTML file highlighting:\n",
        "    - BamHI sites (GGATCC)\n",
        "    - EcoRI sites (GAATTC)\n",
        "    - HindIII sites (AAGCTT)\n",
        "    - Stop codons (TAA, TAG, TGA)\n",
        "    \"\"\"\n",
        "    restriction_sites = {\n",
        "        \"BamHI\": \"GGATCC\",\n",
        "        \"EcoRI\": \"GAATTC\",\n",
        "        \"HindIII\": \"AAGCTT\"\n",
        "    }\n",
        "\n",
        "    stop_codons = [\"TAA\", \"TAG\", \"TGA\"]\n",
        "\n",
        "    with open(output_html, \"w\") as html_file:\n",
        "        # Write HTML header\n",
        "        html_file.write(\"\"\"<!DOCTYPE html>\n",
        "<html lang=\"en\">\n",
        "<head>\n",
        "    <meta charset=\"UTF-8\">\n",
        "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
        "    <title>DNA Sequence Analysis</title>\n",
        "    <style>\n",
        "        body { font-family: monospace; line-height: 1.5; }\n",
        "        .sequence { margin-bottom: 30px; white-space: pre-wrap; word-wrap: break-word; }\n",
        "        .BamHI { background-color: #FFCCCC; font-weight: bold; }\n",
        "        .EcoRI { background-color: #CCFFCC; font-weight: bold; }\n",
        "        .HindIII { background-color: #CCCCFF; font-weight: bold; }\n",
        "        .stop { text-decoration: underline; font-weight: bold; color: red; }\n",
        "        .start { background-color: yellow; color: green; font-weight: bold; }\n",
        "        h2 { border-bottom: 1px solid #ccc; }\n",
        "        .legend { margin-bottom: 20px; }\n",
        "        .legend-item { display: inline-block; margin-right: 15px; }\n",
        "    </style>\n",
        "</head>\n",
        "<body>\n",
        "    <h1>DNA Sequence Analysis</h1>\n",
        "    <div class=\"legend\">\n",
        "        <div class=\"legend-item\"><span class=\"BamHI\">BamHI (GGATCC)</span></div>\n",
        "        <div class=\"legend-item\"><span class=\"EcoRI\">EcoRI (GAATTC)</span></div>\n",
        "        <div class=\"legend-item\"><span class=\"HindIII\">HindIII (AAGCTT)</span></div>\n",
        "        <div class=\"legend-item\"><span class=\"stop\">Stop codons (TAA, TAG, TGA)</span></div>\n",
        "        <div class=\"legend-item\"><span class=\"start\">Start codon (ATG) in frame with BamHI</span></div>\n",
        "    </div>\n",
        "\"\"\")\n",
        "\n",
        "        # Process each sequence\n",
        "        for record in fasta_records:\n",
        "            seq_str = str(record.seq).upper()\n",
        "            html_file.write(f\"<h2>{record.id}</h2>\\n<div class='sequence'>\")\n",
        "\n",
        "            # Find all sites to annotate\n",
        "            annotations = []\n",
        "\n",
        "            # Find restriction sites\n",
        "            for site_name, site_seq in restriction_sites.items():\n",
        "                for match in re.finditer(site_seq, seq_str):\n",
        "                    start, end = match.span()\n",
        "                    annotations.append((start, end, f\"class='{site_name}'\"))\n",
        "\n",
        "            # Find BamHI site for reference\n",
        "            bamhi_match = re.search(\"GGATCC\", seq_str)\n",
        "            if bamhi_match:\n",
        "                bamhi_end = bamhi_match.end()\n",
        "                bamhi_start = bamhi_match.start()\n",
        "\n",
        "                # Find in-frame ATG start codons upstream of BamHI\n",
        "                # Calculate the frame of BamHI site\n",
        "                frame_offset = bamhi_start % 3\n",
        "\n",
        "                # Look for ATG codons upstream of BamHI that are in the same frame\n",
        "                for i in range(bamhi_start - 3, -1, -3):  # Go backwards by codon\n",
        "                    if i >= 0 and i + 2 < len(seq_str):  # Make sure we have a full codon\n",
        "                        codon = seq_str[i:i+3]\n",
        "                        if codon == \"ATG\" and i % 3 == frame_offset:\n",
        "                            annotations.append((i, i+3, \"class='start'\"))\n",
        "\n",
        "                # Only highlight stop codons in the same reading frame as BamHI\n",
        "                for i in range(bamhi_end, len(seq_str) - 2, 3):  # Start from BamHI end, increment by 3\n",
        "                    codon = seq_str[i:i+3]\n",
        "                    if codon in stop_codons:\n",
        "                        annotations.append((i, i+3, \"class='stop'\"))\n",
        "            else:\n",
        "                # If no BamHI site, just look for stop codons in all frames\n",
        "                for i in range(0, len(seq_str) - 2, 3):\n",
        "                    codon = seq_str[i:i+3]\n",
        "                    if codon in stop_codons:\n",
        "                        annotations.append((i, i+3, \"class='stop'\"))\n",
        "\n",
        "            # Sort annotations by start position\n",
        "            annotations.sort(key=lambda x: x[0])\n",
        "\n",
        "            # Generate HTML with annotations\n",
        "            last_end = 0\n",
        "            for start, end, tag in annotations:\n",
        "                # Add any non-annotated sequence before this annotation\n",
        "                if start > last_end:\n",
        "                    html_file.write(html.escape(seq_str[last_end:start]))\n",
        "\n",
        "                # Add the annotated sequence\n",
        "                html_file.write(f\"<span {tag}>{html.escape(seq_str[start:end])}</span>\")\n",
        "                last_end = end\n",
        "\n",
        "            # Add any remaining sequence after the last annotation\n",
        "            if last_end < len(seq_str):\n",
        "                html_file.write(html.escape(seq_str[last_end:]))\n",
        "\n",
        "            html_file.write(\"</div>\\n\")\n",
        "\n",
        "        # Write HTML footer\n",
        "        html_file.write(\"</body>\\n</html>\")\n",
        "\n",
        "def translate_sequences(fasta_records, output_file):\n",
        "    \"\"\"\n",
        "    Translate the DNA sequences starting exactly at the BamHI site (including it).\n",
        "    Save as FASTA format with clean headers.\n",
        "    \"\"\"\n",
        "    bamhi_site = \"GGATCC\"\n",
        "    translated_records = []\n",
        "\n",
        "    for record in fasta_records:\n",
        "        seq_str = str(record.seq).upper()\n",
        "        bamhi_match = re.search(bamhi_site, seq_str)\n",
        "\n",
        "        if bamhi_match:\n",
        "            # Start translation from the BamHI site itself (include GGATCC in translation)\n",
        "            start_pos = bamhi_match.start()\n",
        "\n",
        "            # Get the coding sequence starting from BamHI site\n",
        "            coding_seq = seq_str[start_pos:]\n",
        "\n",
        "            # Translate the sequence\n",
        "            protein_seq = Seq(coding_seq).translate(to_stop=True)\n",
        "\n",
        "            # Create a new record for the protein sequence with clean header\n",
        "            translated_records.append({\n",
        "                \"id\": record.id,\n",
        "                \"seq\": str(protein_seq)\n",
        "            })\n",
        "        else:\n",
        "            print(f\"Warning: No BamHI site found in sequence {record.id}\")\n",
        "\n",
        "    # Write translated sequences with clean headers\n",
        "    with open(output_file, \"w\") as f:\n",
        "        # First write an informational comment (not part of any sequence)\n",
        "        f.write(\"# Translated protein sequences starting at BamHI site\\n\")\n",
        "\n",
        "        # Write each sequence with clean header\n",
        "        for record in translated_records:\n",
        "            f.write(f\">{record['id']}\\n\")\n",
        "            # Write protein sequence with 60 characters per line\n",
        "            seq = record['seq']\n",
        "            for i in range(0, len(seq), 60):\n",
        "                f.write(f\"{seq[i:i+60]}\\n\")\n",
        "\n",
        "    return translated_records\n",
        "\n",
        "# Run the main process\n",
        "print(\"\\nFASTA Processing Script for Google Colab\\n\")\n",
        "\n",
        "# Pre-filled directory path\n",
        "default_path = \"/content/drive/MyDrive/Fasta-files/GeneArt-summary-2025AAH3KF\"\n",
        "directory = input(f\"Enter the path to the directory in Google Drive containing FASTA files (press Enter to use default: {default_path}): \") or default_path\n",
        "\n",
        "# Find all FASTA files\n",
        "print(f\"\\nSearching for FASTA files in: {directory}\")\n",
        "fasta_files = find_fasta_files(directory)\n",
        "print(f\"Found {len(fasta_files)} FASTA files:\")\n",
        "for file in fasta_files[:5]:  # Show first 5 files\n",
        "    print(f\"  - {file}\")\n",
        "if len(fasta_files) > 5:\n",
        "    print(f\"  ... and {len(fasta_files) - 5} more\")\n",
        "\n",
        "if not fasta_files:\n",
        "    print(\"No FASTA files found. Please check the directory path and try again.\")\n",
        "else:\n",
        "    # Create output directory within the input directory\n",
        "    output_dir_name = \"GeneArt_analysis_output\"\n",
        "    output_dir = os.path.join(directory, output_dir_name)\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    print(f\"\\nCreated output directory: {output_dir}\")\n",
        "\n",
        "    # Define output files\n",
        "    compiled_fasta = os.path.join(output_dir, \"compiled_sequences.fasta\")\n",
        "    processing_log = os.path.join(output_dir, \"processing_details.log\")\n",
        "    annotated_html = os.path.join(output_dir, \"annotated_sequences.html\")\n",
        "    translated_fasta = os.path.join(output_dir, \"translated_sequences.fasta\")\n",
        "\n",
        "    # Compile sequences\n",
        "    print(\"\\nCompiling sequences with clean headers...\")\n",
        "    fasta_records = compile_fasta_sequences(fasta_files, compiled_fasta, processing_log)\n",
        "    print(f\"Compiled {len(fasta_records)} sequences saved to {compiled_fasta}\")\n",
        "    print(f\"Detailed processing information saved to {processing_log}\")\n",
        "\n",
        "    # Create annotated HTML\n",
        "    print(\"\\nCreating annotated HTML file...\")\n",
        "    analyze_dna_sequences(fasta_records, annotated_html)\n",
        "    print(f\"Annotated sequences saved to {annotated_html}\")\n",
        "\n",
        "    # Translate sequences\n",
        "    translated_fasta = os.path.join(output_dir, \"translated_sequences.fasta\")\n",
        "    print(\"\\nTranslating sequences...\")\n",
        "    translate_sequences(fasta_records, translated_fasta)\n",
        "    print(f\"Translated sequences saved to {translated_fasta}\")\n",
        "\n",
        "    print(\"\\nProcessing complete! All files saved to:\", output_dir)\n",
        "    print(\"You can access these files directly in your Google Drive.\")"
      ]
    }
  ]
}