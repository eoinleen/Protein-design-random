{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1AGdu2Si8M3XFfeDfSFWMNxXFQ1qscyTC",
      "authorship_tag": "ABX9TyNdHm2a+e/iTTaamRz/zKbG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eoinleen/Protein-design-random/blob/main/Copy_of_Total_analysis_RFdiff_v3_ind-err_578.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "1W_jgO35bMgY",
        "outputId": "9adbf53d-43ca-4299-e36c-f37b23bd19bf"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "unindent does not match any outer indentation level (<tokenize>, line 578)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<tokenize>\"\u001b[0;36m, line \u001b[0;32m578\u001b[0m\n\u001b[0;31m    fig.update_layout(\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "RFdiffusion Structure Analysis and Sequence Extraction Tool\n",
        "========================================================\n",
        "Created: January 31, 2025\n",
        "Authors: Original Analysis - Dr. Eoin Leen, University of Leeds\n",
        "         Visualization & Integration - Claude AI & Dr. Eoin Leen\n",
        "Version: 2.0\n",
        "\n",
        "Purpose:\n",
        "--------\n",
        "Combined pipeline for:\n",
        "1. Structural analysis of PDB files\n",
        "2. AF2 score visualization\n",
        "3. Sequence extraction and formatting\n",
        "4. Generation of publication-ready visualizations\n",
        "\n",
        "Input Required:\n",
        "-------------\n",
        "1. Directory containing PDB files\n",
        "2. af2_scores.csv file in same directory containing:\n",
        "   - design: Design number\n",
        "   - n: Sequence number\n",
        "   - seq: Sequences in format \"sequence1/sequence2\"\n",
        "   - i_pae: iPAE scores\n",
        "   - Other AF2 metrics\n",
        "\n",
        "Output Generated:\n",
        "---------------\n",
        "1. PowerPoint presentation with:\n",
        "   - Slide 1: Structure-function correlation plots\n",
        "   - Slide 2: iPAE score visualization\n",
        "   - Slide 3: Top 10 sequences by iPAE score\n",
        "   - Slide 4: Detailed interface analysis for structures with i_PAE < 7.5\n",
        "2. Combined FASTA file with all sequences\n",
        "3. CSV file with combined structural analysis\n",
        "\n",
        "Analysis Parameters:\n",
        "------------------\n",
        "1. Hydrogen Bonds:\n",
        "   - Distance cutoff: O-N distance < 3.5 Å\n",
        "   - Calculated between backbone atoms only\n",
        "   - Only inter-chain H-bonds counted\n",
        "\n",
        "2. Salt Bridges:\n",
        "   - Distance cutoff: < 4.0 Å between any atoms of residue pairs\n",
        "   - Residue pairs considered:\n",
        "     * Acidic: ASP, GLU\n",
        "     * Basic: LYS, ARG, HIS\n",
        "   - Only inter-chain salt bridges counted\n",
        "\n",
        "3. Hydrophobic Contacts:\n",
        "   - Distance cutoff: < 5.0 Å between any atoms of residue pairs\n",
        "   - Hydrophobic residues considered:\n",
        "     * ALA, VAL, LEU, ILE, MET, PHE, TRP, PRO\n",
        "   - Only inter-chain contacts counted\n",
        "\n",
        "4. Buried Surface Area:\n",
        "   - Calculated using FreeSASA algorithm\n",
        "   - Uses default atomic radii from FreeSASA (based on NACCESS/RSA)\n",
        "   - Process:\n",
        "     * First calculates SASA for entire complex\n",
        "     * Then calculates SASA for each chain individually\n",
        "     * BSA = (Sum of individual chain SASAs - Complex SASA) / 2\n",
        "   - Units: Å²\n",
        "   - Inter-chain burial only (interface area)\n",
        "   - Probe radius: 1.4 Å (water molecule)\n",
        "   - Resolution: 100 points/atom (FreeSASA default)\n",
        "\n",
        "5. Interface Analysis (for structures with i_PAE < 7.5):\n",
        "   - Core Region: Residues with >90% SASA burial upon complex formation\n",
        "   - Rim Region: Residues with 10-90% SASA burial\n",
        "   - Residue Classification:\n",
        "     * Hydrophobic: ALA, VAL, LEU, ILE, MET, PHE, TRP, PRO\n",
        "     * Polar: SER, THR, ASN, GLN, TYR, CYS\n",
        "     * Charged: ASP, GLU, LYS, ARG, HIS\n",
        "   - SASA calculated using FreeSASA with default parameters\n",
        "     * Probe radius: 1.4 Å\n",
        "     * Per-residue SASA summed from atomic areas\n",
        "\n",
        "6. Clash Score:\n",
        "   - Calculated as clashes per 1000 atoms\n",
        "   - Clash defined as: non-bonded atoms closer than sum of vdW radii - 0.4 Å\n",
        "   - Only inter-chain clashes considered\n",
        "   - Hydrogen atoms excluded\n",
        "   - Van der Waals radii used:\n",
        "     * C: 1.7 Å\n",
        "     * N: 1.55 Å\n",
        "     * O: 1.52 Å\n",
        "     * S: 1.8 Å\n",
        "     * P: 1.8 Å\n",
        "     * Halogens: F: 1.47 Å, Cl: 1.75 Å, Br: 1.85 Å, I: 1.98 Å\n",
        "\"\"\"\n",
        "\n",
        "# Install required packages\n",
        "!pip install -q biopython pandas freesasa numpy matplotlib seaborn python-pptx plotly kaleido\n",
        "\n",
        "# Import required libraries\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import files, drive\n",
        "from pathlib import Path\n",
        "from typing import Dict, List, Optional, Tuple, Any\n",
        "from Bio import PDB\n",
        "from Bio.PDB.PDBIO import PDBIO\n",
        "from Bio.PDB.Polypeptide import is_aa\n",
        "from Bio.PDB.Structure import Structure\n",
        "import freesasa\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from pptx import Presentation\n",
        "from pptx.util import Inches, Cm, Pt\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "# Custom exception for structure validation\n",
        "class StructureValidationError(Exception):\n",
        "    pass\n",
        "# ===============================\n",
        "# Structure Analysis Functions\n",
        "# ===============================\n",
        "\n",
        "def validate_pdb_file(file_path: str) -> bool:\n",
        "    \"\"\"Validates if file exists and has proper PDB format.\"\"\"\n",
        "    if not os.path.exists(file_path):\n",
        "        raise FileNotFoundError(f\"PDB file not found: {file_path}\")\n",
        "    try:\n",
        "        with open(file_path, 'r') as f:\n",
        "            first_line = f.readline()\n",
        "            if not any(marker in first_line for marker in ['HEADER', 'ATOM', 'MODEL']):\n",
        "                raise StructureValidationError(f\"Invalid PDB: {file_path}\")\n",
        "    except UnicodeDecodeError:\n",
        "        raise StructureValidationError(f\"Not a valid text file: {file_path}\")\n",
        "    return True\n",
        "\n",
        "def safe_structure_load(parser: PDB.PDBParser, file_path: str) -> Optional[Structure]:\n",
        "    \"\"\"Safely loads PDB structure with error handling.\"\"\"\n",
        "    try:\n",
        "        validate_pdb_file(file_path)\n",
        "        structure = parser.get_structure('protein', file_path)\n",
        "        if not list(structure.get_models()):\n",
        "            raise StructureValidationError(\"No models\")\n",
        "        if not list(list(structure.get_models())[0].get_chains()):\n",
        "            raise StructureValidationError(\"No chains\")\n",
        "        return structure\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading {file_path}: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "def calculate_buried_surface_area(pdb_file: str) -> Tuple[Optional[float], Optional[Dict[str, float]]]:\n",
        "    \"\"\"Calculates buried surface area between chains.\"\"\"\n",
        "    parser = PDB.PDBParser(QUIET=True)\n",
        "    structure = safe_structure_load(parser, pdb_file)\n",
        "    if not structure:\n",
        "        return None, None\n",
        "    try:\n",
        "        chains = list(structure.get_chains())\n",
        "        if len(chains) < 2:\n",
        "            print(f\"Warning: {pdb_file} has fewer than 2 chains\")\n",
        "            return None, None\n",
        "\n",
        "        combined_structure = freesasa.Structure(pdb_file)\n",
        "        result = freesasa.calc(combined_structure)\n",
        "        total_area = result.totalArea()\n",
        "\n",
        "        chain_areas = {}\n",
        "        io = PDBIO()\n",
        "        temp_files = []\n",
        "\n",
        "        for chain in chains:\n",
        "            new_structure = PDB.Structure.Structure('temp')\n",
        "            new_model = PDB.Model.Model(0)\n",
        "            new_structure.add(new_model)\n",
        "            new_model.add(chain.copy())\n",
        "\n",
        "            temp_file = f\"temp_chain_{chain.id}.pdb\"\n",
        "            temp_files.append(temp_file)\n",
        "\n",
        "            io.set_structure(new_structure)\n",
        "            io.save(temp_file)\n",
        "\n",
        "            chain_structure = freesasa.Structure(temp_file)\n",
        "            chain_result = freesasa.calc(chain_structure)\n",
        "            chain_areas[chain.id] = chain_result.totalArea()\n",
        "\n",
        "        for temp_file in temp_files:\n",
        "            if os.path.exists(temp_file):\n",
        "                os.remove(temp_file)\n",
        "\n",
        "        total_individual_area = sum(chain_areas.values())\n",
        "        buried_surface_area = abs(total_individual_area - total_area) / 2\n",
        "        return buried_surface_area, chain_areas\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error calculating BSA for {pdb_file}: {str(e)}\")\n",
        "        return None, None\n",
        "\n",
        "def calculate_hydrogen_bonds(structure: Structure) -> int:\n",
        "    \"\"\"Calculates number of hydrogen bonds between chains.\"\"\"\n",
        "    try:\n",
        "        h_bonds = 0\n",
        "        for chain1 in structure.get_chains():\n",
        "            for chain2 in structure.get_chains():\n",
        "                if chain1.id >= chain2.id:\n",
        "                    continue\n",
        "                for res1 in chain1.get_residues():\n",
        "                    if not is_aa(res1):\n",
        "                        continue\n",
        "                    for res2 in chain2.get_residues():\n",
        "                        if not is_aa(res2):\n",
        "                            continue\n",
        "                        if 'O' in res1 and 'N' in res2:\n",
        "                            distance = res1['O'] - res2['N']\n",
        "                            if distance < 3.5:\n",
        "                                h_bonds += 1\n",
        "        return h_bonds\n",
        "    except Exception as e:\n",
        "        print(f\"Error calculating H-bonds: {str(e)}\")\n",
        "        return 0\n",
        "def calculate_hydrophobic_contacts(structure: Structure) -> int:\n",
        "    \"\"\"\n",
        "    Calculates number of hydrophobic contacts between chains.\n",
        "    Considers residues ALA, VAL, LEU, ILE, MET, PHE, TRP, PRO.\n",
        "    Contact is counted if distance < 5.0 Å.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        hydrophobic_residues = {'ALA', 'VAL', 'LEU', 'ILE', 'MET', 'PHE', 'TRP', 'PRO'}\n",
        "        contacts = 0\n",
        "        for chain1 in structure.get_chains():\n",
        "            for chain2 in structure.get_chains():\n",
        "                if chain1.id >= chain2.id:\n",
        "                    continue\n",
        "                for res1 in chain1.get_residues():\n",
        "                    if not is_aa(res1) or res1.get_resname() not in hydrophobic_residues:\n",
        "                        continue\n",
        "                    for res2 in chain2.get_residues():\n",
        "                        if not is_aa(res2) or res2.get_resname() not in hydrophobic_residues:\n",
        "                            continue\n",
        "                        min_distance = float('inf')\n",
        "                        for atom1 in res1.get_atoms():\n",
        "                            for atom2 in res2.get_atoms():\n",
        "                                distance = atom1 - atom2\n",
        "                                min_distance = min(min_distance, distance)\n",
        "                        if min_distance < 5.0:\n",
        "                            contacts += 1\n",
        "        return contacts\n",
        "    except Exception as e:\n",
        "        print(f\"Error calculating hydrophobic contacts: {str(e)}\")\n",
        "        return 0\n",
        "\n",
        "def calculate_salt_bridges(structure: Structure) -> int:\n",
        "    \"\"\"\n",
        "    Calculates number of salt bridges between chains.\n",
        "    Salt bridge is counted between ASP/GLU and LYS/ARG/HIS if distance < 4.0 Å.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        acidic = {'ASP', 'GLU'}\n",
        "        basic = {'LYS', 'ARG', 'HIS'}\n",
        "        salt_bridges = 0\n",
        "        for chain1 in structure.get_chains():\n",
        "            for chain2 in structure.get_chains():\n",
        "                if chain1.id >= chain2.id:\n",
        "                    continue\n",
        "                for res1 in chain1.get_residues():\n",
        "                    if not is_aa(res1):\n",
        "                        continue\n",
        "                    res1_name = res1.get_resname()\n",
        "                    for res2 in chain2.get_residues():\n",
        "                        if not is_aa(res2):\n",
        "                            continue\n",
        "                        res2_name = res2.get_resname()\n",
        "                        if ((res1_name in acidic and res2_name in basic) or\n",
        "                            (res1_name in basic and res2_name in acidic)):\n",
        "                            min_distance = float('inf')\n",
        "                            for atom1 in res1.get_atoms():\n",
        "                                for atom2 in res2.get_atoms():\n",
        "                                    distance = atom1 - atom2\n",
        "                                    min_distance = min(min_distance, distance)\n",
        "                            if min_distance < 4.0:\n",
        "                                salt_bridges += 1\n",
        "        return salt_bridges\n",
        "    except Exception as e:\n",
        "        print(f\"Error calculating salt bridges: {str(e)}\")\n",
        "        return 0\n",
        "\n",
        "def save_results_as_df(results: List[Dict[str, Any]], output_file: str) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Converts analysis results to DataFrame and saves to CSV.\n",
        "    Extracts design and variant numbers from filenames.\n",
        "    \"\"\"\n",
        "    analysis_data = []\n",
        "    for result in results:\n",
        "        filename = result['file_name'].replace('.pdb', '')\n",
        "        try:\n",
        "            design_num = int(filename.split('design')[1].split('_')[0])\n",
        "            variant_num = int(filename.split('_n')[1])\n",
        "            analysis_data.append({\n",
        "                'design': design_num,\n",
        "                'n': variant_num,\n",
        "                'buried_surface_area': result['buried_surface_area'] if result['buried_surface_area'] else 0,\n",
        "                'hydrogen_bonds': result['hydrogen_bonds'],\n",
        "                'hydrophobic_contacts': result['hydrophobic_contacts'],\n",
        "                'salt_bridges': result['salt_bridges']\n",
        "            })\n",
        "        except Exception as e:\n",
        "            print(f\"Error parsing filename {filename}: {str(e)}\")\n",
        "            continue\n",
        "\n",
        "    df = pd.DataFrame(analysis_data)\n",
        "    df = df.sort_values(['design', 'n']).reset_index(drop=True)\n",
        "    df.to_csv(output_file, index=False)\n",
        "    print(f\"Saved structure analysis to {output_file}\")\n",
        "    return df\n",
        "\n",
        "def merge_with_af2_scores(structure_df: pd.DataFrame, af2_scores_file: str) -> pd.DataFrame:\n",
        "    \"\"\"Merges structural analysis results with AF2 scores.\"\"\"\n",
        "    af2_df = pd.read_csv(af2_scores_file)\n",
        "    merged_df = pd.merge(af2_df, structure_df, on=['design', 'n'], how='left')\n",
        "    merged_df = merged_df.sort_values(['design', 'n']).reset_index(drop=True)\n",
        "    return merged_df\n",
        "# ===============================\n",
        "# Interface Analysis Functions\n",
        "# ===============================\n",
        "\n",
        "def calculate_residue_sasa(structure: Structure, chain_id: str, complex: bool = True) -> Dict[str, float]:\n",
        "    \"\"\"\n",
        "    Calculates SASA for each residue in a chain.\n",
        "\n",
        "    Args:\n",
        "        structure: PDB Structure object\n",
        "        chain_id: Chain identifier\n",
        "        complex: If True, calculates SASA in context of complex; if False, treats chain in isolation\n",
        "\n",
        "    Returns:\n",
        "        Dictionary of residue IDs and their SASA values\n",
        "    \"\"\"\n",
        "    # Create temporary PDB for SASA calculation\n",
        "    io = PDBIO()\n",
        "    if not complex:\n",
        "        # Create new structure with just the chain of interest\n",
        "        new_structure = PDB.Structure.Structure('temp')\n",
        "        new_model = PDB.Model.Model(0)\n",
        "        new_structure.add(new_model)\n",
        "        target_chain = structure[0][chain_id]\n",
        "        new_model.add(target_chain)\n",
        "        structure = new_structure\n",
        "\n",
        "    io.set_structure(structure)\n",
        "    temp_file = f\"temp_sasa_{chain_id}.pdb\"\n",
        "    io.save(temp_file)\n",
        "\n",
        "    # Calculate SASA\n",
        "    freesasa_struct = freesasa.Structure(temp_file)\n",
        "    result = freesasa.calc(freesasa_struct)\n",
        "\n",
        "    # Get per-residue SASA\n",
        "    residue_sasa = {}\n",
        "    chain = structure[0][chain_id]\n",
        "    for residue in chain:\n",
        "        res_id = f\"{residue.get_resname()}_{residue.id[1]}\"\n",
        "        sasa = sum(result.residueAreas()[chain_id].residueAreas[residue.id[1]].total)\n",
        "        residue_sasa[res_id] = sasa\n",
        "\n",
        "    # Cleanup\n",
        "    os.remove(temp_file)\n",
        "    return residue_sasa\n",
        "\n",
        "def analyze_interface_details(structure: Structure) -> Dict:\n",
        "    \"\"\"\n",
        "    Performs comprehensive interface analysis.\n",
        "\n",
        "    Calculates:\n",
        "    1. Core/Rim classification (>90% burial for core, 10-90% for rim)\n",
        "    2. Residue composition analysis\n",
        "    3. Interface shape parameters\n",
        "    \"\"\"\n",
        "    results = {}\n",
        "\n",
        "    # Residue classifications\n",
        "    hydrophobic = {'ALA', 'VAL', 'LEU', 'ILE', 'MET', 'PHE', 'TRP', 'PRO'}\n",
        "    polar = {'SER', 'THR', 'ASN', 'GLN', 'TYR', 'CYS'}\n",
        "    charged = {'ASP', 'GLU', 'LYS', 'ARG', 'HIS'}\n",
        "\n",
        "    core_residues = {'hydrophobic': 0, 'polar': 0, 'charged': 0}\n",
        "    rim_residues = {'hydrophobic': 0, 'polar': 0, 'charged': 0}\n",
        "\n",
        "    # Analyze each chain\n",
        "    for chain in structure.get_chains():\n",
        "        # Calculate SASA for isolated chain\n",
        "        monomer_sasa = calculate_residue_sasa(structure, chain.id, complex=False)\n",
        "        # Calculate SASA in complex\n",
        "        complex_sasa = calculate_residue_sasa(structure, chain.id, complex=True)\n",
        "\n",
        "        for residue_id, monomer_value in monomer_sasa.items():\n",
        "            if monomer_value < 0.1:  # Skip buried residues\n",
        "                continue\n",
        "\n",
        "            complex_value = complex_sasa.get(residue_id, 0)\n",
        "            burial_percent = (monomer_value - complex_value) / monomer_value * 100\n",
        "\n",
        "            # Get residue type\n",
        "            res_name = residue_id.split('_')[0]\n",
        "            if res_name in hydrophobic:\n",
        "                res_type = 'hydrophobic'\n",
        "            elif res_name in polar:\n",
        "                res_type = 'polar'\n",
        "            elif res_name in charged:\n",
        "                res_type = 'charged'\n",
        "            else:\n",
        "                continue\n",
        "\n",
        "            # Classify as core or rim\n",
        "            if burial_percent > 90:\n",
        "                core_residues[res_type] += 1\n",
        "            elif burial_percent > 10:\n",
        "                rim_residues[res_type] += 1\n",
        "\n",
        "    # Calculate statistics\n",
        "    total_core = sum(core_residues.values())\n",
        "    total_rim = sum(rim_residues.values())\n",
        "\n",
        "    results = {\n",
        "        'core_count': total_core,\n",
        "        'rim_count': total_rim,\n",
        "        'core_rim_ratio': total_core / max(1, total_rim),\n",
        "        'core_hydrophobic': round(100 * core_residues['hydrophobic'] / max(1, total_core)),\n",
        "        'core_polar': round(100 * core_residues['polar'] / max(1, total_core)),\n",
        "        'core_charged': round(100 * core_residues['charged'] / max(1, total_core)),\n",
        "        'rim_hydrophobic': round(100 * rim_residues['hydrophobic'] / max(1, total_rim)),\n",
        "        'rim_polar': round(100 * rim_residues['polar'] / max(1, total_rim)),\n",
        "        'rim_charged': round(100 * rim_residues['charged'] / max(1, total_rim))\n",
        "    }\n",
        "\n",
        "    return results\n",
        "\n",
        "def create_clash_score(structure: Structure) -> float:\n",
        "    \"\"\"\n",
        "    Calculates clash score for structure.\n",
        "\n",
        "    Clash defined as:\n",
        "    - Non-bonded atoms closer than sum of van der Waals radii minus 0.4Å\n",
        "    - Only considers inter-chain clashes\n",
        "    - Hydrogens not considered\n",
        "    \"\"\"\n",
        "    # Van der Waals radii (Å)\n",
        "    vdw_radii = {\n",
        "        'C': 1.7, 'N': 1.55, 'O': 1.52, 'S': 1.8,\n",
        "        'P': 1.8, 'F': 1.47, 'Cl': 1.75, 'Br': 1.85, 'I': 1.98\n",
        "    }\n",
        "\n",
        "    clash_count = 0\n",
        "    total_atoms = 0\n",
        "\n",
        "    # Iterate through chain pairs\n",
        "    chains = list(structure.get_chains())\n",
        "    for i, chain1 in enumerate(chains):\n",
        "        for chain2 in chains[i+1:]:\n",
        "            # Get heavy atoms\n",
        "            atoms1 = [atom for atom in chain1.get_atoms()\n",
        "                     if atom.element != 'H' and atom.element in vdw_radii]\n",
        "            atoms2 = [atom for atom in chain2.get_atoms()\n",
        "                     if atom.element != 'H' and atom.element in vdw_radii]\n",
        "\n",
        "            # Check for clashes\n",
        "            for atom1 in atoms1:\n",
        "                for atom2 in atoms2:\n",
        "                    distance = atom1 - atom2\n",
        "                    min_distance = vdw_radii[atom1.element] + vdw_radii[atom2.element] - 0.4\n",
        "\n",
        "                    if distance < min_distance:\n",
        "                        clash_count += 1\n",
        "\n",
        "            total_atoms += len(atoms1) + len(atoms2)\n",
        "\n",
        "    # Calculate clashes per 1000 atoms\n",
        "    clash_score = (1000 * clash_count) / max(1, total_atoms)\n",
        "    return clash_score\n",
        "# ===============================\n",
        "# Visualization Functions\n",
        "# ===============================\n",
        "\n",
        "def create_pptx_plots(df: pd.DataFrame, output_dir: str, timestamp: str):\n",
        "    \"\"\"\n",
        "    Creates PowerPoint presentation with four slides:\n",
        "    1. Structure-function correlation plots\n",
        "    2. iPAE visualization\n",
        "    3. Top 10 lowest iPAE sequences\n",
        "    4. Detailed interface analysis for low iPAE structures\n",
        "    \"\"\"\n",
        "    # Initialize presentation\n",
        "    prs = Presentation()\n",
        "    prs.slide_width = Cm(21)\n",
        "    prs.slide_height = Cm(29.7)\n",
        "\n",
        "    # First slide - correlation plots\n",
        "    print(\"Creating correlation plots...\")\n",
        "    slide1 = prs.slides.add_slide(prs.slide_layouts[5])\n",
        "\n",
        "    fig, axes = plt.subplots(3, 2, figsize=(8.27, 11.69))\n",
        "    axes = axes.flatten()\n",
        "\n",
        "    y_vars = ['i_ptm', 'rmsd', 'buried_surface_area',\n",
        "              'hydrogen_bonds', 'hydrophobic_contacts', 'salt_bridges']\n",
        "    titles = ['iPTM', 'RMSD (Å)', 'Buried Surface Area (Å²)',\n",
        "             '# of Hydrogen Bonds', '# of Hydrophobic Contacts', '# of Salt Bridges']\n",
        "\n",
        "    for ax, y_var, title in zip(axes, y_vars, titles):\n",
        "        sns.scatterplot(data=df, x='i_pae', y=y_var, ax=ax, color='black', marker='x', s=16)\n",
        "        ax.set_xlabel('i_PAE')\n",
        "        ax.set_ylabel(title)\n",
        "        ax.set_title(title)\n",
        "        ax.set_facecolor('white')\n",
        "\n",
        "    fig.patch.set_facecolor('white')\n",
        "    plt.tight_layout()\n",
        "\n",
        "    temp_img1 = os.path.join(output_dir, 'temp_plots1.png')\n",
        "    plt.savefig(temp_img1, bbox_inches='tight', dpi=300, facecolor='white')\n",
        "    plt.close()\n",
        "\n",
        "    left = Cm(2)\n",
        "    top = Cm(2)\n",
        "    slide1.shapes.add_picture(temp_img1, left, top)\n",
        "\n",
        "    # Second slide - iPAE visualization\n",
        "    print(\"Creating iPAE visualization...\")\n",
        "    slide2 = prs.slides.add_slide(prs.slide_layouts[5])\n",
        "\n",
        "    fig = make_subplots(\n",
        "        rows=4,\n",
        "        cols=1,\n",
        "        vertical_spacing=0.08,\n",
        "        subplot_titles=[f\"Designs {i*8}-{(i+1)*8-1}\" for i in range(4)]\n",
        "    )\n",
        "\n",
        "    rows_per_subplot = 512  # 8 designs × 64 sequences = 512 rows per subplot\n",
        "    colors = ['black', 'red']\n",
        "\n",
        "    for i in range(4):\n",
        "        start_idx = i * rows_per_subplot\n",
        "        end_idx = start_idx + rows_per_subplot\n",
        "        chunk = df.iloc[start_idx:end_idx].copy()\n",
        "\n",
        "        for design_num in chunk['design'].unique():\n",
        "            mask = chunk['design'] == design_num\n",
        "            color = colors[design_num % 2]\n",
        "\n",
        "            fig.add_trace(\n",
        "                go.Bar(\n",
        "                    x=chunk[mask].index,\n",
        "                    y=chunk[mask]['i_pae'],\n",
        "                    showlegend=False,\n",
        "                    marker_color=color,\n",
        "                    width=1,\n",
        "                ),\n",
        "                row=i+1,\n",
        "                col=1\n",
        "            )\n",
        "fig.update_yaxes(\n",
        "            range=[0, 30],\n",
        "            title_text='iPAE' if i == 1 else None,\n",
        "            row=i+1,\n",
        "            col=1\n",
        "        )\n",
        "\n",
        "        design_numbers = sorted(chunk['design'].unique())\n",
        "        fig.update_xaxes(\n",
        "            tickmode='array',\n",
        "            ticktext=design_numbers,\n",
        "            tickvals=[start_idx + (j*64) + 32 for j in range(len(design_numbers))],\n",
        "            row=i+1,\n",
        "            col=1,\n",
        "            title_text='Design Number' if i == 3 else None\n",
        "        )\n",
        "\n",
        "    fig.update_layout(\n",
        "        title='iPAE Scores by Design Number and Sequence (Scale: 0-30)',\n",
        "        height=1000,\n",
        "        width=1200,\n",
        "        showlegend=False,\n",
        "        margin=dict(t=50, b=50, r=150, l=50),\n",
        "        paper_bgcolor='white',\n",
        "        plot_bgcolor='white'\n",
        "    )\n",
        "\n",
        "    temp_img2 = os.path.join(output_dir, 'temp_plots2.png')\n",
        "    fig.write_image(temp_img2)\n",
        "\n",
        "    left = Cm(1)\n",
        "    top = Cm(1)\n",
        "    slide2.shapes.add_picture(temp_img2, left, top)\n",
        "\n",
        "    # Third slide - Top 10 sequences\n",
        "    print(\"Creating top 10 sequences slide...\")\n",
        "    slide3 = prs.slides.add_slide(prs.slide_layouts[5])\n",
        "\n",
        "    # Get top 10 lowest i_PAE sequences\n",
        "    top_10_sequences = df.nsmallest(10, 'i_pae')[['design', 'n', 'i_pae', 'seq']]\n",
        "\n",
        "    # Add title\n",
        "    title = slide3.shapes.title\n",
        "    title.text = \"Top 10 Sequences (Lowest i_PAE Scores)\"\n",
        "\n",
        "    # Create text box for sequences\n",
        "    left = Cm(2)\n",
        "    top = Cm(4)\n",
        "    width = Cm(17)\n",
        "    height = Cm(20)\n",
        "    textbox = slide3.shapes.add_textbox(left, top, width, height)\n",
        "    text_frame = textbox.text_frame\n",
        "    text_frame.clear()\n",
        "\n",
        "    # Add sequences\n",
        "    for _, row in top_10_sequences.iterrows():\n",
        "        sequence = row['seq'].split('/')[1].strip()\n",
        "        p = text_frame.add_paragraph()\n",
        "        p.text = f\">d{row['design']}n{row['n']} (i_PAE: {row['i_pae']:.4f})\\n{sequence}\"\n",
        "        p.font.name = 'Courier New'\n",
        "        p.font.size = Pt(8)\n",
        "        p.line_spacing = 1.0\n",
        "\n",
        "    # Fourth slide - Detailed interface analysis\n",
        "    print(\"Creating interface analysis for low i_PAE structures...\")\n",
        "    slide4 = prs.slides.add_slide(prs.slide_layouts[5])\n",
        "\n",
        "    # Add title\n",
        "    title = slide4.shapes.title\n",
        "    title.text = \"Detailed Interface Analysis (Structures with i_PAE < 7.5)\"\n",
        "\n",
        "    # Create text box\n",
        "    left = Cm(2)\n",
        "    top = Cm(4)\n",
        "    width = Cm(17)\n",
        "    height = Cm(20)\n",
        "    textbox = slide4.shapes.add_textbox(left, top, width, height)\n",
        "    text_frame = textbox.text_frame\n",
        "    text_frame.clear()\n",
        "\n",
        "    # Get low i_PAE structures\n",
        "    low_ipae_structures = df[df['i_pae'] < 7.5].sort_values('i_pae')\n",
        "\n",
        "    if len(low_ipae_structures) == 0:\n",
        "        p = text_frame.add_paragraph()\n",
        "        p.text = \"No structures found with i_PAE < 7.5\"\n",
        "        p.font.name = 'Courier New'\n",
        "        p.font.size = Pt(8)\n",
        "    else:\n",
        "        parser = PDB.PDBParser(QUIET=True)\n",
        "\n",
        "        for _, row in low_ipae_structures.iterrows():\n",
        "            pdb_file = os.path.join(os.path.dirname(output_dir),\n",
        "                                  f\"design{row['design']}_n{row['n']}.pdb\")\n",
        "            structure = safe_structure_load(parser, pdb_file)\n",
        "\n",
        "            if structure:\n",
        "                interface_analysis = analyze_interface_details(structure)\n",
        "                clash_score = create_clash_score(structure)\n",
        "\n",
        "                p = text_frame.add_paragraph()\n",
        "                p.text = (\n",
        "                    f\"Structure d{row['design']}n{row['n']} (i_PAE: {row['i_pae']:.2f})\\n\"\n",
        "                    f\"Buried Surface Area: {row['buried_surface_area']:.1f} Å²\\n\"\n",
        "                    f\"Clash Score: {clash_score:.2f}\\n\"\n",
        "                    f\"Interface Analysis:\\n\"\n",
        "                    f\"  Core Residues: {interface_analysis['core_count']}\\n\"\n",
        "                    f\"  Rim Residues: {interface_analysis['rim_count']}\\n\"\n",
        "                    f\"  Core/Rim ratio: {interface_analysis['core_rim_ratio']:.2f}\\n\"\n",
        "                    f\"  Core Composition:\\n\"\n",
        "                    f\"    Hydrophobic: {interface_analysis['core_hydrophobic']}%\\n\"\n",
        "                    f\"    Polar: {interface_analysis['core_polar']}%\\n\"\n",
        "                    f\"    Charged: {interface_analysis['core_charged']}%\\n\"\n",
        "                    f\"  Rim Composition:\\n\"\n",
        "                    f\"    Hydrophobic: {interface_analysis['rim_hydrophobic']}%\\n\"\n",
        "                    f\"    Polar: {interface_analysis['rim_polar']}%\\n\"\n",
        "                    f\"    Charged: {interface_analysis['rim_charged']}%\\n\"\n",
        "                    f\"----------------------------------------\\n\"\n",
        "                )\n",
        "                p.font.name = 'Courier New'\n",
        "                p.font.size = Pt(8)\n",
        "                p.line_spacing = 1.0\n",
        "\n",
        "    # Save PowerPoint\n",
        "    output_basename = os.path.basename(output_dir)\n",
        "    pptx_path = os.path.join(output_dir, f\"{output_basename}_{timestamp}_analysis.pptx\")\n",
        "    prs.save(pptx_path)\n",
        "\n",
        "    # Clean up temporary files\n",
        "    os.remove(temp_img1)\n",
        "    os.remove(temp_img2)\n",
        "    print(f\"Saved PowerPoint to {pptx_path}\")\n",
        "# ===============================\n",
        "# Main Processing Functions\n",
        "# ===============================\n",
        "\n",
        "def process_multiple_pdb_files(pdb_directory: str, af2_scores_file: str = None) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Main processing function that:\n",
        "    1. Analyzes all PDB files in directory\n",
        "    2. Merges with AF2 scores\n",
        "    3. Generates visualizations and outputs\n",
        "    4. Saves sequences to FASTA\n",
        "    \"\"\"\n",
        "    if not os.path.exists(pdb_directory):\n",
        "        raise FileNotFoundError(f\"Directory not found: {pdb_directory}\")\n",
        "\n",
        "    # Get timestamp for file naming\n",
        "    timestamp = time.strftime(\"%y%m%d\")\n",
        "\n",
        "    # Initialize results\n",
        "    results = []\n",
        "    parser = PDB.PDBParser(QUIET=True)\n",
        "    pdb_files = [f for f in os.listdir(pdb_directory) if f.endswith('.pdb')]\n",
        "\n",
        "    if not pdb_files:\n",
        "        print(f\"No PDB files found in {pdb_directory}\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    print(f\"Processing {len(pdb_files)} PDB files...\")\n",
        "    total_files = len(pdb_files)\n",
        "\n",
        "    # Process each PDB file\n",
        "    for idx, file_name in enumerate(pdb_files, 1):\n",
        "        pdb_file = os.path.join(pdb_directory, file_name)\n",
        "        print(f\"Processing file {idx}/{total_files}: {file_name}\")\n",
        "\n",
        "        structure = safe_structure_load(parser, pdb_file)\n",
        "        if not structure:\n",
        "            continue\n",
        "\n",
        "        # Calculate structural parameters\n",
        "        buried_surface_area, chain_areas = calculate_buried_surface_area(pdb_file)\n",
        "        h_bonds = calculate_hydrogen_bonds(structure)\n",
        "        hydrophobic = calculate_hydrophobic_contacts(structure)\n",
        "        salt_bridges = calculate_salt_bridges(structure)\n",
        "\n",
        "        results.append({\n",
        "            'file_name': file_name,\n",
        "            'buried_surface_area': buried_surface_area,\n",
        "            'hydrogen_bonds': h_bonds,\n",
        "            'hydrophobic_contacts': hydrophobic,\n",
        "            'salt_bridges': salt_bridges,\n",
        "            'chain_areas': chain_areas\n",
        "        })\n",
        "\n",
        "    # Save structural analysis\n",
        "    output_basename = os.path.basename(pdb_directory)\n",
        "    structure_csv = os.path.join(pdb_directory, f\"{output_basename}_{timestamp}_structure.csv\")\n",
        "    structure_df = save_results_as_df(results, structure_csv)\n",
        "\n",
        "    # If AF2 scores exist, merge and create visualizations\n",
        "    if af2_scores_file and os.path.exists(af2_scores_file):\n",
        "        print(f\"Merging with AF2 scores from {af2_scores_file}\")\n",
        "        final_df = merge_with_af2_scores(structure_df, af2_scores_file)\n",
        "\n",
        "        # Save combined analysis\n",
        "        combined_csv = os.path.join(pdb_directory, f\"{output_basename}_{timestamp}_combined.csv\")\n",
        "        final_df.to_csv(combined_csv, index=False)\n",
        "        print(f\"Saved combined results to {combined_csv}\")\n",
        "\n",
        "        # Create PowerPoint plots\n",
        "        create_pptx_plots(final_df, pdb_directory, timestamp)\n",
        "\n",
        "        # Save sequences to FASTA\n",
        "        fasta_path = os.path.join(pdb_directory, f\"{output_basename}_{timestamp}_sequences.fasta\")\n",
        "        with open(fasta_path, 'w') as f:\n",
        "            for _, row in final_df.iterrows():\n",
        "                sequence = row['seq'].split('/')[1].strip()\n",
        "                header = f\">d{row['design']}n{row['n']}\"\n",
        "                f.write(f\"{header}\\n{sequence}\\n\")\n",
        "        print(f\"Saved sequences to {fasta_path}\")\n",
        "\n",
        "        return final_df\n",
        "    return structure_df\n",
        "\n",
        "# ===============================\n",
        "# Main Execution\n",
        "# ===============================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Mount Google Drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    # Set directory containing PDB files and AF2 scores\n",
        "    pdb_directory = '/content/drive/MyDrive/PDB-files/202501xx/3NOB-70-110-all_pdb'  # Update this path\n",
        "    af2_scores_path = os.path.join(pdb_directory, 'af2_scores.csv')\n",
        "\n",
        "    if not os.path.exists(af2_scores_path):\n",
        "        af2_scores_path = None\n",
        "        print(\"No AF2 scores file found - will generate structure analysis only\")\n",
        "\n",
        "    print(\"\\nStarting analysis...\")\n",
        "    print(f\"Processing PDB files from: {pdb_directory}\")\n",
        "\n",
        "    try:\n",
        "        results_df = process_multiple_pdb_files(pdb_directory, af2_scores_path)\n",
        "        print(\"\\nAnalysis completed successfully!\")\n",
        "    except Exception as e:\n",
        "        print(f\"\\nError during analysis: {str(e)}\")\n",
        "        raise\n",
        "\n"
      ]
    }
  ]
}